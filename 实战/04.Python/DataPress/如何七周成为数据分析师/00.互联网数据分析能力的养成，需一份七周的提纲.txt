第一周：Excel学习掌握
如果Excel玩的顺溜，你可以略过这一周。不过介于我入行时也不会vlookup，所以有必要讲下。

重点是了解各种函数，包括但不限于sum，count，sumif，countif，find，if，left/right，时间转换等。

Excel函数不需要学全，重要的是学会搜索。即如何将遇到的问题在搜索引擎上描述清楚。

我认为掌握vlookup和数据透视表足够，是最具性价比的两个技巧。

学会vlookup，SQL中的join，Python中的merge很容易理解。

学会数据透视表，SQL中的group，Python中的pivot_table也是同理。

这两个搞定，基本10万条以内的数据统计没啥难度，80%的办公室白领都能秒杀。

Excel是熟能生巧，多找练习题。还有需要养成好习惯，不要合并单元格，不要过于花哨。表格按照原始数据（sheet1）、加工数据（sheet2），图表（sheet3）的类型管理。

下面是为了以后更好的基础而附加的学习任务：

了解单元格格式，后期的数据类型包括各类timestamp，date，string，int，bigint，char，factor，float等。
了解数组，以及怎么用（excel的数组挺难用），Python和R也会涉及到 list。
了解函数和参数，当进阶为编程型的数据分析师时，会让你更快的掌握。
了解中文编码，UTF8和ASCII，包括CSV的delimiter等，以后你会回来感谢我的。
这一周的内容我会拆分成两部分：函数篇和技巧篇。

这是一道练习题，我给你1000个身份证号码，告诉我里面有多少男女，各省市人口的分布，这些人的年龄和星座。如果能完成上述过程，那么这一周就直接略过吧。（身份证号码规律可以网上搜索）

第二周：数据可视化
数据分析界有一句经典名言，字不如表，表不如图。数据可视化是数据分析的主要方向之一。除掉数据挖掘这类高级分析，不少数据分析就是监控数据观察数据。

数据分析的最终都是要兜售自己的观点和结论的。兜售的最好方式就是做出观点清晰数据详实的PPT给老板看。如果没人认同分析结果，那么分析也不会被改进和优化，不落地的数据分析价值又在哪里？

首先要了解常用的图表：

0 (2)

Excel的图表可以100%完成上面的图形要求，但这只是基础。后续的进阶可视化，势必要用到编程绘制。为什么？比如常见的多元分析，你能用Excel很轻松的完成？但是在IPython只需要一行代码。

0 (1)

其次掌握BI，下图是微软的BI。

f3f96c223a492c62ce376544a7c2f0fd_b

BI（商业智能）和图表的区别在于BI擅长交互和报表，更擅长解释已经发生和正在发生的数据。将要发生的数据是数据挖掘的方向。

BI的好处在于很大程度解放数据分析师的工作，推动全部门的数据意识，另外降低其他部门的数据需求（万恶的导数据）。

BI市面上的产品很多，基本都是建立仪表盘Dashboard，通过维度的联动和钻取，获得可视化的分析。

最后需要学习可视化和信息图的制作。

0

这是安（装）身（逼）立（加）命（薪）之本。这和数据本事没有多大关系，更看重审美、解读、PPT、信息化的能力。但值得花一点时间去学习。

数据可视化的学习就是三个过程：

了解数据（图表）
整合数据（BI）
展示数据（信息化）
第三周：分析思维的训练
这周轻松一下，学学理论知识。

好的数据分析首先要有结构化的思维，也就是我们俗称的金字塔思维。思维导图是必备的工具。

之后再了解SMART、5W2H、SWOT、4P理论、六顶思考帽等框架。这些框架都是大巧不工的经典。

分析也是有框架和方法论的，主要围绕三个要点展开：

一个业务没有指标，则不能增长和分析；
好的指标应该是比率或比例；
好的分析应该对比或关联。
举一个例子：我告诉你一家超市今天有1000人的客流量，你会怎么分析？

这1000人的数量，和附近其他超市比是多是少？（对比）
这1000人的数量比昨天多还是少？（对比）
1000人有多少产生了实际购买？（转化比例）
路过超市，超市外的人流是多少？（转化比例）
这是一个快速搭建分析框架的方法。如果只看1000人，是看不出分析不出任何结果。

优秀的数据分析师会拷问别人的数据，而他本身的分析也是经得起拷问，这就是分析思维能力。需要确切明白的是，一周时间锻炼不出数据思维，只能做到了解。数据思维是不断练习的结果，我只是尽量缩短这个过程。

第四周：数据库学习
Excel对十万条以内的数据处理起来没有问题，但是互联网行业就是不缺数据。但凡产品有一点规模，数据都是百万起。这时候就需要学习数据库。

越来越多的产品和运营岗位，会在招聘条件中，将会SQL作为优先的加分项。

SQL是数据分析的核心技能之一，从Excel到SQL绝对是数据处理效率的一大进步。

学习围绕Select展开。增删改、约束、索引、数据库范式均可以跳过。

主要了解where，group by，order by，having，like，count，sum，min，max，distinct，if，join，left join，limit，and和or的逻辑，时间转换函数等。

如果想要跟进一步，可以学习row_number，substr，convert，contact等。另外不同数据平台的函数会有差异，例如Presto和phpMyAdmin。

再有点追求，就去了解Explain优化，了解SQL的工作原理，了解数据类型，了解IO。以后就可以和技术研发们谈笑风生，毕竟将“这里有bug”的说话，换成“这块的数据死锁了”，逼格大大的不同。

SQL的学习主要是多练，网上寻找相关的练习题，刷一遍就差不多了。

第五周：统计知识学习
很遗憾，统计知识也是我薄弱的地方，可这是数据分析的基础。

我看过很多产品和运营相关的数据分析文章，没有多少提及统计知识。这是不严谨的。

比如产品的AB测试，如果产品经理并不清楚置信度的含义和概念，那么好的效果并不意味着真正的好。尤其是5%这种非显著的提高。

比如运营一次活动，运营若不了解检验相关的概念，那么如何去判别活动在数据上是有效果还是没有效果？别说平均数。

再讨论一下经典的概率问题，如果一个人获流感，实验结果为阳性的概率为90%；如果没有获流感，实验结果为阳性的概率为9%。现在这个人检验结果为阳性，他有多少几率是得了流感？

如果你觉得几率有50%、60%、70%等等，那么都犯了直觉性的错误。它还和得病的基础概率有关。

统计知识会教我们以另一个角度看待数据。如果大家了解过《统计数据会撒谎》，那么就知道很多数据分析的决策并不牢靠。

我们需要花一周的时间掌握描述性统计，包括均值、中位数、标准差、方差、概率、假设检验、显著性、总体和抽样等概念。

不需要学习更高阶的统计知识，谁让我们是速成呢。只要做到不会被数据欺骗，不犯错误就好。

以Excel的分析工具库举例（图片网上找来）。在初级的统计学习中，需要了解列1的各名词含义，而不是停留在平均数这个基础上。

9cce8bdc0d4484c62ab68228dd77822e_b

第六周：业务知识（用户行为、产品、运营）
这一周需要了解业务。对于数据分析师来说，业务的了解比数据方法论更重要。当然很遗憾，业务学习没有捷径。

我举一个数据沙龙上的例子，一家O2O配送公司发现在重庆地区，外卖员的送货效率低于其他城市，导致用户的好评率降低。总部的数据分析师建立了各个指标去分析原因，都没有找出来问题。后来在访谈中发觉，因为重庆是山城，路面高低落差比较夸张，很多外卖人员的小电瓶上不了坡…所以导致送货效率慢。

这个案例中，我们只知道送货员的送货水平距离，即POI数据，根本不可能知道垂直距离的数据。这就是数据的局限，也是只会看数据的分析师和接地气分析师的最大差异。

对业务市场的了解是数据分析在工作经验上最大的优势之一。不同行业领域的业务知识都不一样，我就不献丑了。在互联网行业，有几个宽泛的业务数据需要了解。

产品数据分析，以经典的AAARR框架学习，了解活跃留存的指标和概念（这些内容，我的历史文章已经涉及了部分）。

并且数据分析师需要知道如何用SQL计算。因为在实际的分析过程中，留存只是一个指标，通过userId 关联和拆分才是常见的分析策略。

网站数据分析，可以抽象吃一个哲学问题：

用户从哪里来（SEO／SEM），用户到哪里去（访问路径），用户是谁（用户画像／用户行为路径）。

虽然网站已经不是互联网的主流，但现在有很多APP+Web的复合框架，朋友圈的传播活动肯定需要用到网页的指标去分析。

用户数据分析，这是数据化运营的一种应用。

在产品早期，可以通过埋点计算转化率，利用AB测试达到快速迭代的目的，在积累到用户量的后期，利用埋点去分析用户行为，并且以此建立用户分层用户画像等。

例如用贝叶斯算法计算用户的性别概率，用K聚类算法划分用户的群体，用行为数据作为特征建立响应模型等。不过快速入门不需要掌握这些，只需要有一个大概的框架概念。

除了业务知识，业务层面的沟通也很重要。在业务线足够长的时候，我不止一次遇到产品和运营没有掌握所有的业务要点，尤其涉及跨部门的分析。良好的业务沟通能力是数据分析的基础能力。

第七周：Python/R 学习
终于到第七周，也是最痛苦的一周。这时应该学习编程技巧。

是否具备编程能力，是初级数据分析和高级数据分析的风水岭。数据挖掘，爬虫，可视化报表都需要用到编程能力（例如上文的多元散点图）。掌握一门优秀的编程语言，可以让数据分析师事半功倍，升职加薪，迎娶白富美。

以时下最热门的R语言和Python为学习支线，速成只要学习一条。

我刚好两类都学过。R的优点是统计学家编写的，缺点也是统计学家编写。如果是各类统计函数的调用，绘图，分析的前验性论证，R无疑有优势。但是大数据量的处理力有不逮，学习曲线比较陡峭。Python则是万能的胶水语言，适用性强，可以将各类分析的过程脚本化。Pandas，SKLearn等各包也已经追平R。

学习R，需要了解数据结构（matrix，array，data.frame，list等）、数据读取，图形绘制( ggplot2)、数据操作、统计函数(mean,median,sd,var,scale等)。高阶的统计暂时不用去涉及，这是后续的学习任务。

R语言的开发环境建议用RStudio。

学习Python有很多分支，我们专注数据分析这块。需要了解调用包、函数、数据类型(list,tuple,dict)，条件判断，迭代等。高阶的Numpy和Pandas在有精力的情况下涉及。

Python的开发环境建议Anaconda，可以规避掉环境变量、包安装等大部分新手问题。Mac自带Python2.7，但现在Python 3已经比几年前成熟，没有编码问题，就不要抱成守旧了。

对于没有技术基础的运营和产品，第七周最吃力，虽然SQL＋Excel足够应付入门级数据分析，但是涉及到循环迭代、多元图表的分析部分，复杂度就呈几何上升。更遑论数据挖掘这种高阶玩法。

我也相信，未来了解数据挖掘的产品和运营会有极强的竞争力。

到这里，刚刚好是七周。如果还需要第八周+，则是把上面的巩固和融会贯通，毕竟这只是目的性极强的速成，是开始，而不是数据分析的毕业典礼。

如果希望数据分析能力更近一步，或者成为优秀的数据分析师，每一周的内容都能继续学习至精通。实际上，业务知识、统计知识仅靠两周是非常不牢固的。

再往后的学习，会有许多分支。比如偏策划的数据产品经理，比如偏统计的机器学习，比如偏商业的市场分析师，比如偏工程的大数据工程师。这是后话了。