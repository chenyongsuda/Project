1. 数据存在哪些质量问题
  # 需要调整的columns,包括column的字段多空格啊等
  # 数据丢失 有一些行是none啊等
  # 数据值无效或者异常值
  # 重复行
  # 需要处理后才能分析的列

2. 一般通过
df.columns 看出columns的一些情况
df.shape() 看出一共多少数据
df.info() 看一看出各列非none多少行等信息
df.xxx.value_counts(dropna=False) 判断某列值的评率
df.discribe() 查看数值型类的均值最大最小等信息

3.统计数据可视化
比如直方图
      df.xxxxxx.plot('hist')
      import matplotlib.pyplot as plt
      plt.show()
      这样直接看图中的异常值.
      通过df[df.xxxxxx > xxxxx]来浏览数据
      
比如箱线图可以看出异常点和25,50,75,100范围值
      Histograms are great ways of visualizing single variables. To visualize multiple variables, boxplots are useful, 
      especially when one of the variables is categorical.
      # Create the boxplot
      df.boxplot(column='initial_cost', by='Borough', rot=90)
      
 点图比较适合两个比较
      Boxplots are great when you have a numeric column that you want to compare across different categories. When you want to visualize two numeric columns, scatter plots are ideal.
      # Import necessary modules
      import pandas as pd
      import matplotlib.pyplot as plt
      # Create and display the first scatter plot
      df.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)
      plt.show()
      # Create and display the second scatter plot
      df_subset.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)
      plt.show()
4. 整洁的数据包含哪几方面
    每个变量作为单独的列。
    Each variable as a separate column.
    每行作为一个单独的观察。
    Each row as a separate observation.
    使用pd.melt方法类似于转置操作,将列的值转置为行数据,含义是将多列溶解为类型列一个值域
    
    举例:
    In this exercise, you will practice melting a DataFrame using pd.melt(). There are two parameters you should be aware of: 
    id_vars and value_vars. The id_vars represent the columns of the data you do not want to melt (i.e., keep it in its current shape), 
    while the value_vars represent the columns you do wish to melt into rows. By default, if no value_vars are provided, 
    all columns not set in the id_vars will be melted. This could save a bit of typing, 
    depending on the number of columns that need to be melted.
    # Melt airquality: airquality_melt
    airquality_melt = pd.melt(airquality, id_vars=['Month','Day'])
    
    # Melt airquality: airquality_melt
    Melt the columns of airquality with the defaultvariablecolumn renamed to'measurement'and the defaultvaluecolumn renamed to'reading'. 
    You can do this by specifying, respectively, thevarnameandvaluename` parameters.
    airquality_melt = pd.melt(airquality, id_vars=['Month', 'Day'], var_name='measurement', value_name='reading')
    
    melt的反向操作pivot
    # Pivot airquality_melt: airquality_pivot
    # pivot_table() has an index parameter which you can use to specify the columns that you don't want pivoted: 
    # It is similar to the id_vars parameter of pd.melt(). Two other parameters that you have to specify are columns
    # (the name of the column you want to pivot), and values (the values to be used when the column is pivoted). 
    # The melted DataFrame airquality_melt has been pre-loaded for you.
    airquality_pivot = airquality_melt.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading')
    
    pivot后Index会变成复合Index
    可以参考下层次化索引
    参考 https://blog.csdn.net/sinat_29957455/article/details/79028730
    层次化索引(hierarchical indexing)是pandas的一个重要的功能，它可以在一个轴上有多个（两个以上）的索引，这就表示着，它能够以低维度形式来表示高维度的数据。
    #There's a very simple method you can use to get back the original DataFrame from the pivoted DataFrame:
    .reset_index(). Dan didn't show you how to use this method in the video, 
    but you're now going to practice using it in this exercise to get back the original DataFrame from airquality_pivot,
    which has been pre-loaded.
    airquality_pivot_reset = airquality_pivot.reset_index()
    
    pivot后如果数据有多条的话需要使用聚合函数
    # Pivot table the airquality_dup: airquality_pivot 
    airquality_pivot = airquality_dup.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading', aggfunc=np.mean)
    
    切分字段：
    In order to parse this value, you need to extract the first letter into a new column for gender, 
    and the rest into a column for age_group. Here, since you can parse values by position, 
    you can take advantage of pandas' vectorized string slicing by using the str attribute of columns of type object.
    # Melt tb: tb_melt
    tb_melt = pd.melt(tb, id_vars=['country', 'year'])
    # Create the 'gender' column
    tb_melt['gender'] = tb_melt.variable.str[0]
    # Create the 'age_group' column
    tb_melt['age_group'] = tb_melt.variable.str[1:]
    # Print the head of tb_melt
    print(tb_melt.head())
  
    进入某个字段使用str进入后如果是string的话可以使用string特有的操作 如果是list的话可以使用list的一些操作比如get(0) get(1)等
    例子：
    # Melt ebola: ebola_melt
    ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='type_country', value_name='counts')
    print(ebola_melt)
    # Create the 'str_split' column
    ebola_melt['str_split'] = ebola_melt.type_country.str.split('_')
    # Create the 'type' column
    ebola_melt['type'] = ebola_melt.str_split.str[0]
    # Create the 'country' column
    ebola_melt['country'] = ebola_melt.str_split.str[1]
    # Print the head of ebola_melt
    print(ebola_melt.head())
    
    合并数据源,可以行级别合并和列级别合并
    # Row级别合并
    # Concatenate uber1, uber2, and uber3: row_concat
    row_concat = pd.concat([uber1,uber2,uber3])
    
    # Column级别合并
    # Concatenate ebola_melt and status_country column-wise: ebola_tidy
    ebola_tidy = pd.concat([ebola_melt,status_country],axis=1)
    
    # 忽略index合并,不忽略的话index重复,忽略的话自动生成新的index
    # Concatenate uber1, uber2, and uber3: row_concat
    row_concat = pd.concat([uber1,uber2,uber3],ignore_index=true)
    
    
==================================================================================
层次化索引
一、层次化索引
层次化索引(hierarchical indexing)是pandas的一个重要的功能，它可以在一个轴上有多个（两个以上）的索引，这就表示着，它能够以低维度形式来表示高维度的数据。

二、Series的层次化索引
    # Series的层次化索引，索引是一个二维数组，相当于两个索引决定一个值
    # 有点类似于DataFrame的行索引和列索引
    s = Series(np.arange(1,10),index=[["a","a","a","b","b","c","c","d","d"],
                                      [1,2,3,1,2,3,1,2,3]])
    print(s)
    '''
    a  1    1
       2    2
       3    3
    b  1    4
       2    5
    c  3    6
       1    7
    d  2    8
       3    9
    '''
    #显示层次化索引
    print(s.index)
    '''
    MultiIndex(levels=[['a', 'b', 'c', 'd'], [1, 2, 3]],
           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 1, 2, 0, 1, 2]])
    '''
    #选取第一个索引为a的数据
    print(s["a"])
    '''
    1    1
    2    2
    3    3
    '''
    #层次化索引的切片，包括右端的索引
    print(s["c":"d"])#等价于s.ix[["c","d"]]
    '''
    c  3    6
       1    7
    d  2    8
       3    9
    '''
    print(type(s))
    #<class 'pandas.core.series.Series'>
    print(type(s.unstack()))
    #<class 'pandas.core.frame.DataFrame'>
    #通过unstack方法可以将Series变成一个DataFrame
    #数据的类型以及数据的输出结构都变成了DataFrame，对于不存在的位置使用NaN填充
    print(s.unstack())
    '''
         1    2    3
    a  1.0  2.0  3.0
    b  4.0  5.0  NaN
    c  7.0  NaN  6.0
    d  NaN  8.0  9.0
    '''
    #通过stack方法，可以将DataFrame变成Series，它是unstack的逆运算
    print(type(s.unstack().stack()))
    #<class 'pandas.core.series.Series'>
    print(s.unstack().stack())
    '''
    a  1    1.0
       2    2.0
       3    3.0
    b  1    4.0
       2    5.0
    c  1    7.0
       3    6.0
    d  2    8.0
       3    9.0
    '''
二、DataFrame的层次化索引
对于DataFrame来说，行和列都能够进行层次化索引。

    #DataFrame的行和列都是用层次化索引
    #也就是四个索引来决定一个值，将一个二维数据变成了一个四维数据
    data = DataFrame(np.arange(12).reshape(4,3),
                     index=[["a","a","b","b"],[1,2,1,2]],
                     columns=[["A","A","B"],["Z","X","C"]])
    print(data)
    '''
         A       B
         Z   X   C
    a 1  0   1   2
      2  3   4   5
    b 1  6   7   8
      2  9  10  11
    '''
    #选取列,参数只能选取"A"或"B"
    print(data["A"])#等价于data.ix[:,"A"]
    '''
         Z   X
    a 1  0   1
      2  3   4
    b 1  6   7
      2  9  10
    '''
    #选取行
    print(data.ix["a"])
    '''
       A     B
       Z  X  C
    1  0  1  2
    2  3  4  5
    '''
三、重排分级顺序
在使用层次化索引的时候，我们可以重新调整某条轴上各级别的顺序，或根据级别上的值对数据进行排序。swaplevel接受两个级别编号或名称，返回一个互换了级别的新对象（数据不变）。我们可以对每个级别设置一个名称，就像对DataFrame设置行列索引的名称一样。

    data = DataFrame(np.arange(12).reshape(4,3),
                     index=[["a","a","b","b"],[1,2,1,2]],
                     columns=[["A","A","B"],["Z","X","C"]])
    print(data)
    '''
         A       B
         Z   X   C
    a 1  0   1   2
      2  3   4   5
    b 1  6   7   8
      2  9  10  11
    '''
    #对每一个级别设置一个名称
    #设置行级别的名称
    data.index.names=["row1","row2"]
    #设置列级别的名称
    data.columns.names=["column1","column2"]
    print(data)
    '''
    column1    A       B
    column2    Z   X   C
    row1 row2
    a    1     0   1   2
         2     3   4   5
    b    1     6   7   8
         2     9  10  11
    '''
    #通过swaplevel，调整行的顺序
    print(data.swaplevel("row1","row2"))
    '''
    column1    A       B
    column2    Z   X   C
    row2 row1
    1    a     0   1   2
    2    a     3   4   5
    1    b     6   7   8
    2    b     9  10  11
    '''
    #对指定级别中的值进行排序
    #对级别名称为row2中的值进行排序
    print(data.sortlevel(1))#等价于data.swaplevel(0,1).sortlevel(0)
    '''
    column1    A       B
    column2    Z   X   C
    row1 row2           
    a    1     0   1   2
    b    1     6   7   8
    a    2     3   4   5
    b    2     9  10  11
    '''
四、根据级别汇总统计
    data = DataFrame(np.arange(12).reshape(4,3),
                     index=[["a","a","b","b"],[1,2,1,2]],
                     columns=[["A","A","B"],["Z","X","C"]])
    print(data)
    '''
         A       B
         Z   X   C
    a 1  0   1   2
      2  3   4   5
    b 1  6   7   8
      2  9  10  11
    '''
    #对每一个级别设置一个名称
    #设置行级别的名称
    data.index.names=["row1","row2"]
    #设置列级别的名称
    data.columns.names=["column1","column2"]
    print(data)
    '''
    column1    A       B
    column2    Z   X   C
    row1 row2
    a    1     0   1   2
         2     3   4   5
    b    1     6   7   8
         2     9  10  11
    '''
    #指定行级别的名称进行求和
    print(data.sum(level="row1"))
    '''
    column1   A       B
    column2   Z   X   C
    row1
    a         3   5   7
    b        15  17  19
    '''
    #指定列级别的名称进求和
    print(data.sum(level="column1",axis=1))
    '''
    column1     A   B
    row1 row2        
    a    1      1   2
         2      7   5
    b    1     13   8
         2     19  11

