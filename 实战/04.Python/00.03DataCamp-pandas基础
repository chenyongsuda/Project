# Pandas 基础
      
      如下解答中说明了dataframe的values为numpy的ndarray
      
      # Import numpy
      import numpy as np

      # Create array of DataFrame values: np_vals
      np_vals = df.values

      # Create new array of base 10 logarithm values: np_vals_log10
      np_vals_log10 = np.log10(np_vals)

      # Create array of new DataFrame by passing df to np.log10(): df_log10
      df_log10 = np.log10(df)

      # Print original and new data containers
      [print(x, 'has type', type(eval(x))) for x in ['np_vals', 'np_vals_log10', 'df', 'df_log10']]
      
      输出：
          np_vals has type <class 'numpy.ndarray'>
          np_vals_log10 has type <class 'numpy.ndarray'>
          df has type <class 'pandas.core.frame.DataFrame'>
          df_log10 has type <class 'pandas.core.frame.DataFrame'>
          
#构造DataFrame方式
    1. 通过map来构造
    
    2. read_csv
    
    3. 也是通过map
        通过column的list和值的list进行zip
        然后通过map强制转为map 再用map构造为dataframe
        参考：
        zipped = list(zip(list_keys,list_values))
        # Inspect the list using print()
        print(zipped)
        # Build a dictionary with the zipped list: data
        data = dict(zipped)
        # Build and inspect a DataFrame from the dictionary: df
        df = pd.DataFrame(data)

#Dataframe的index和column可修改(relabeling特征)
    df.index = []
    df.columns = []

#Dataframe的值的传播特征
    # Make a string with the value 'PA': state
    state = 'PA'
    # Construct a dictionary: data
    data = {'state':state, 'city':cities}
    # Construct a DataFrame from dictionary data: df
    df = pd.DataFrame(data)
    
    通过只赋值给state一个值来把其他行的值都赋值了
    

#导入导出dataframe数据
  pd.read_csv(file_path, header=None, names=columns_name,delimiter=' ', index_column=xxx, comment='#', na_values = {columnsname : ['-1']}, prase_data = [[0,1,2]])
  
  可以重制df.index
  可以设置index的name df.index.name
  
  
  写csv的话可以 df.to_csv(out_csv, sep='\t')
  
  
 #Pandas画图
   画图方式可以是
   1.plt.plot(ndarray)
   2.plt.plot(serise)
   3.serise.plot()
   4.dataframe一样有这几种
   
   xxx.plot(color=xxx,style='xxx',legend=True) 等参数
   
   保存
   plt.saveplg(xxx.jpg)
   plt.saveplg(xxx.png)
   plt.saveplg(xxx.pdf)
   可以保存三种
   
#图形密度
      #线形图
      # Create a list of y-axis column names: y_columns
      y_columns = ['AAPL','IBM']
      # Generate a line plot
      df.plot(x='Month', y=y_columns)
      # Add the title
      plt.title('Monthly stock prices')
      # Add the y-axis label
      plt.ylabel('Price ($US)')
      
      #点图
      # Generate a scatter plot
      size为点的大小
      df.plot(kind='scatter', x='hp', y='mpg', s=sizes)
      
      #箱线图
      # Generate the box plots
      subplots表示图片分为多个单独绘制
      df[cols].plot(kind='box',subplots=True)
      
      #PDF 和 CDF 密度话和归一化
      # This formats the plots such that they appear on separate rows
      fig, axes = plt.subplots(nrows=2, ncols=1)
      # Plot the PDF
      df.fraction.plot(ax=axes[0], kind='hist', bins=30, normed=True, range=(0,.3))
      plt.show()
      # Plot the CDF
      df.fraction.plot(ax=axes[1], kind='hist', bins=30, cumulative=True, normed=True, range=(0,.3))
      plt.show()

#数据统计基础
      std	      标准差   标准差能反映一个数据集的离散程度  两组数的集合{0,5,9,14}和{5,6,8,9}其平均值都是7，但第二个集合具有较小的标准差。
      mean	      均值  df.mean(axis='columns') 安装每行计算一个平均值
      median	中位数
      count	非 NA 值的数量
      describe	针对 Series 或 DF 的列计算汇总统计
      min , max	最小值和最大值
      argmin , argmax	最小值和最大值的索引位置（整数）
      idxmin , idxmax	最小值和最大值的索引值
      quantile	样本分位数（0 到 1）                  df.quantile([0.05,0.95])
      sum	求和
      
#数据Bool过滤
      us = df[df.origin=='US']

#loc过滤
      # Generate a box plot of the fare prices for the Third passenger class
      titanic.loc[titanic['pclass'] == 3].plot(ax=axes[2], y='fare', kind='box')
      
#pandas time series
      df1 = pd.read_csv(filename)
      df2 = pd.read_csv(filename, parse_dates=['Date'])
      df3 = pd.read_csv(filename, index_col='Date', parse_dates=True)
      
      只有DF3可以使用df.loc['2010-Aug-01'] 只有将日期表示索引的时候 可以使用df['2018'] 选整年数据  df['2018-01'] 选整年数据 可以用切片选时间段
      
      可以通过pd.to_datetime()创造时间索引数据
      passed the list of strings ['2015-01-01 091234','2015-01-01 091234'] and a format specification variable, such as format='%Y-%m-%d %H%M%S, pandas will parse the string into the proper datetime elements and build the datetime objects.
      
      #创建DataSerise
      # Prepare a format string: time_format
      time_format = '%Y-%m-%d %H:%M'
      # Convert date_list into a datetime object: my_datetimes
      my_datetimes = pd.to_datetime(date_list, format=time_format)  
      # Construct a pandas Series using temperature_list and my_datetimes: time_series
      time_series = pd.Series(temperature_list, index=my_datetimes)
      
      
      #时间Index的使用
      # Extract the hour from 9pm to 10pm on '2010-10-11': ts1
      ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']
      # Extract '2010-07-04' from ts0: ts2
      ts2 = ts0['2010-07-04']
      # Extract data from '2010-12-15' to '2010-12-31': ts3
      ts3 = ts0['2010-12-15':'2010-12-31']
      
      
---------------------------------------------------------------------------------------------------
ReIndex重新索引
reindex()是pandas对象的一个重要方法，其作用是创建一个新索引的新对象。

一、对Series对象重新索引
se1=pd.Series([1,7,3,9],index=['d','c','a','f'])
se1

代码结果：
d    1
c    7
a    3
f    9
dtype: int64


调用reindex将会重新排序，缺失值则用NaN填补。
se2=se1.reindex(['a','b','c','d','e','f'])
se2
1
2
代码结果：

a    3.0
b    NaN
c    7.0
d    1.0
e    NaN
f    9.0
dtype: float64

传入method=” “重新索引时选择插值处理方式：
method=’ffill’或’pad 前向填充

method=’bfill’或’backfill 后向填充

se3=pd.Series(['blue','red','black'],index=[0,2,4])
se4=se3.reindex(range(6),method='ffill')
se4

代码结果：

0     blue
1     blue
2      red
3      red
4    black
5    black
dtype: object

二、对DataFrame对象重新索引
对于DataFrame对象，reindex能修改行索引和列索引。

df1=pd.DataFrame(np.arange(9).reshape(3,3),index=['a','c','d'],columns=['one','two','four'])
df1

代码结果：
one	two	four
a	0	1	2
c	3	4	5
d	6	7	8
默认对行索引重新排序
只传入一个序列不能重新排序列索引

df1.reindex(['a','b','c','d'])
1
代码结果：
one	two	four
a	0.0	1.0	2.0
b	NaN	NaN	NaN
c	3.0	4.0	5.0
d	6.0	7.0	8.0
df1.reindex(index=['a','b','c','d'],columns=['one','two','three','four'])

代码结果：
one	two	three	four
a	0.0	1.0	NaN	2.0
b	NaN	NaN	NaN	NaN
c	3.0	4.0	NaN	5.0
d	6.0	7.0	NaN	8.0
传入fill_value=n用n代替缺失值：
df1.reindex(index=['a','b','c','d'],columns=['one','two','three','four'],fill_value=100)

代码结果：
one	two	three	four
a	0	1	100	2
b	100	100	100	100
c	3	4	100	5
d	6	7	100	8
      
      
--------------------------------------------------------------------
pandas-resample按时间聚合

转化string为date
read_csv(file,prase_dates=['',''])
或者指定
read_csv(file,prase_dates=True,index_col='')

import pandas as pd

#如果需要的话,需将df中的date列转为datetime
df.date = pd.to_datetime(df.date,format="%Y%m%d")

#将改好格式的date列,设置为df的index
df.set_index('date',drop=True)

#按年来提数据  (因为此时的datetime已经为index了,可以直接[]取行内容)
df['2018']
df['2018':'2021']

#按月来提数据
df['2018-01']
df['2018-01':'2018-05']

#按天来提出数据
df['2018-05-24':'2018-09-27']

#按日期汇总数据
resampleing相当于按照时间维度聚合
#将数据以W星期,M月,Q季度,QS季度的开始第一天开始,A年,10A十年,10AS十年聚合日期第一天开始.的形式进行聚合
df.resample('W').sum()
df.resample('M').sum()

#具体某列的数据聚合
df.price.resample('W').sum().fillna(0)   #星期聚合,以0填充NaN值

#某两列
df[['price','num']].resample('W').sum().fillna(0)

#某个时间段内,以W聚合,
df["2018-5":"2018-9"].resample("M").sum().fillna(0)

#rolling 通过rolling方法来平缓值

# Extract data from 2010-Aug-01 to 2010-Aug-15: unsmoothed
unsmoothed = df['Temperature']['2010-Aug-01':'2010-Aug-15']
# Apply a rolling mean with a 24 hour window: smoothed
smoothed = unsmoothed.rolling(window=24).mean()
# Create a new DataFrame with columns smoothed and unsmoothed: august
august = pd.DataFrame({'smoothed':smoothed, 'unsmoothed':unsmoothed})
# Plot both smoothed and unsmoothed data using august.plot().
august.plot()
plt.show()
      
样例2
# Extract the August 2010 data: august
august = df['Temperature']['2010-08']
# Resample to daily data, aggregating by max: daily_highs
daily_highs = august.resample('D').max()
# Use a rolling 7-day window with method chaining to smooth the daily high temperatures in August
daily_highs_smoothed = daily_highs.rolling(window=7).mean()
print(daily_highs_smoothed)

--------------------------------------------------------------------------
各种类型的属性
比如string
xx.str.upper()
xx.str.contains()
xx.dt.hour

缺失值补充
interpolate('liner')

示例：通过reindex给原先缺失的index来补几个日期值,再通过线下补充值来填充
# Reset the index of ts2 to ts1, and then use linear interpolation to fill in the NaNs: ts2_interp
ts2_interp = ts2.reindex(ts1.index).interpolate(how='linear')
# Compute the absolute difference of ts1 and ts2_interp: differences 
differences = np.abs(ts1 - ts2_interp)
# Generate and print summary statistics of the differences
print(differences.describe())

可以通过比较
# Build a Boolean mask to filter out all the 'LAX' departure flights: mask
mask = df['Destination Airport'] == ‘LAX’
或者
df['Destination Airport'].str.contains('LAX')

#时间本地化等转化
# Build a Boolean mask to filter out all the 'LAX' departure flights: mask
mask = df['Destination Airport'] == 'LAX'
# Use the mask to subset the data: la
la = df[mask]
# Combine two columns of data to create a datetime series: times_tz_none 
times_tz_none = pd.to_datetime( la['Date (MM/DD/YYYY)'] + ' ' + la['Wheels-off Time'] )
# Localize the time to US/Central: times_tz_central
times_tz_central = times_tz_none.dt.tz_localize('US/Central')
# Convert the datetimes from US/Central to US/Pacific
times_tz_pacific = times_tz_central.dt.tz_convert('US/Pacific')



      
      
      
      
    
