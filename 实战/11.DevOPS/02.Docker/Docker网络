Docker安装完后默认有三种网络方式

NETWORK ID          NAME                DRIVER              SCOPE
1f84864e599c        bridge              bridge              local
77e7a275fe39        host                host                local
a15f7a19c612        none                null                local

bridge 桥接模式：指NAT桥非物理桥
docker会自动创建docker0桥
如下：
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:1e:54:56:fd brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever

每创建一个容器创建一对网卡一个插在docker0上,一个在容器里面

运行一个容器后查看
[root@digitest01 ~]# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:0c:29:24:7f:ec brd ff:ff:ff:ff:ff:ff
    inet 10.132.250.85/24 brd 10.132.250.255 scope global ens160
       valid_lft forever preferred_lft forever
3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:1e:54:56:fd brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
25: veth02f5188@if24: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default
    link/ether a2:a3:12:60:1c:ac brd ff:ff:ff:ff:ff:ff link-netnsid 0
    
    
看见多一块网卡

安装bridge-utils 工具
yum install -y bridge-utils
[root@digitest01 ~]# brctl show
bridge name     bridge id               STP enabled     interfaces
docker0         8000.02421e5456fd       no              veth02f5188

看到docker0上插了一个veth02f5188

可以从外部看容器的地址 用docker inspect xxx

这样在宿主机内部,容器内部可以互相访问,对于其他外部的机器的访问的话需要将容器的端口暴露并且使用dnat规则加其暴露出来.




host 共享主机模式
表示让容器使用宿主机的网络


None 模式不使用网络,只内部没有网络,表示一个信息孤岛.
有些容器只是批处理不需要网络通信.


一般包含四种模式：
无网络模型,桥接模式,联盟式网络共享一个网络基础,并且这个网络连接到docker01桥(joined container virtual interface),共享物理机的网络的模型.

使用哪种可以指定
docker container --network 指定那三种网络 默认不指定的话是bridge
当然可以使用docker network inspect bridge


=======================================================================================================================
网络名称空间
首先查下ip包是否安装
rpm -q iproute
[root@digitest01 ~]# rpm -q iproute
iproute-4.11.0-14.el7.x86_64

linux的ip命令和ifconfig类似，但前者功能更强大，并旨在取代后者。使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。
ifconfig是net-tools中已被废弃使用的一个命令，许多年前就已经没有维护了。
iproute2套件里提供了许多增强功能的命令，ip命令即是其中之一。

使用ip命令就可以操作了

[root@digitest01 ~]# ip help netns
Usage: ip [ OPTIONS ] OBJECT { COMMAND | help }
       ip [ -force ] -batch filename
where  OBJECT := { link | address | addrlabel | route | rule | neigh | ntable |
                   tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm |
                   netns | l2tp | fou | macsec | tcp_metrics | token | netconf | ila |
                   vrf }
       OPTIONS := { -V[ersion] | -s[tatistics] | -d[etails] | -r[esolve] |
                    -h[uman-readable] | -iec |
                    -f[amily] { inet | inet6 | ipx | dnet | mpls | bridge | link } |
                    -4 | -6 | -I | -D | -B | -0 |
                    -l[oops] { maximum-addr-flush-attempts } | -br[ief] |
                    -o[neline] | -t[imestamp] | -ts[hort] | -b[atch] [filename] |
                    -rc[vbuf] [size] | -n[etns] name | -a[ll] | -c[olor]}


或者使用
[root@digitest01 ~]# ip netns help
Usage: ip netns list
       ip netns add NAME
       ip netns set NAME NETNSID
       ip [-all] netns delete [NAME]
       ip netns identify [PID]
       ip netns pids NAME
       ip [-all] netns exec [NAME] cmd ...
       ip netns monitor
       ip netns list-id

实验开始自建一个网络空间
[root@digitest01 ~]# ip netns add r1
[root@digitest01 ~]# ip netns add r2

查看所有的网络空间
[root@digitest01 ~]# ip netns list
r2
r1
在r1的网络空间中执行ifconfig

[root@digitest01 ~]# ip netns exec r1 ifconfig -a
lo: flags=8<LOOPBACK>  mtu 65536
        loop  txqueuelen 1  (Local Loopback)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
可以看到只有一个lo地址没配置没激活.

现在我们已经有两个网络空间了,那我们可以创建两个虚拟网卡对
把人工分配到网络名称空间中
使用ip link创建一堆虚拟网卡
[root@digitest01 ~]# ip link add name vth1.1 type veth peer name vth1.2
[root@digitest01 ~]# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:0c:29:24:7f:ec brd ff:ff:ff:ff:ff:ff
    inet 10.132.250.85/24 brd 10.132.250.255 scope global ens160
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:1e:54:56:fd brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
28: vth1.2@vth1.1: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 96:80:2c:f2:d6:2c brd ff:ff:ff:ff:ff:ff
29: vth1.1@vth1.2: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 3e:a1:d0:f2:18:1a brd ff:ff:ff:ff:ff:ff
可以看到一堆虚拟网卡创建出来了


首先把虚拟网卡vth1.2挪到r2中
[root@digitest01 ~]# ip link set dev vth1.2 netns r2
然后ip link show查看剩余的
[root@digitest01 ~]# ip link show
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000
    link/ether 00:0c:29:24:7f:ec brd ff:ff:ff:ff:ff:ff
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default
    link/ether 02:42:1e:54:56:fd brd ff:ff:ff:ff:ff:ff
29: vth1.1@if28: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
    link/ether 3e:a1:d0:f2:18:1a brd ff:ff:ff:ff:ff:ff link-netnsid 1
或者使用 ip addr

[root@digitest01 ~]# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:0c:29:24:7f:ec brd ff:ff:ff:ff:ff:ff
    inet 10.132.250.85/24 brd 10.132.250.255 scope global ens160
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:1e:54:56:fd brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
29: vth1.1@if28: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
    link/ether 3e:a1:d0:f2:18:1a brd ff:ff:ff:ff:ff:ff link-netnsid 1


在去看R2中
[root@digitest01 ~]# ip netns exec r2 ifconfig -a
lo: flags=8<LOOPBACK>  mtu 65536
        loop  txqueuelen 1  (Local Loopback)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

vth1.2: flags=4098<BROADCAST,MULTICAST>  mtu 1500
        ether 96:80:2c:f2:d6:2c  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
        
看到这里面显示的名字叫vth1.2也可以改名的,通过命令ip netns exec r2 ip link set env vth1.2 name eht0
[root@digitest01 ~]# ip netns exec r2 ip link set dev  vth1.2 name eth0
[root@digitest01 ~]# ip netns exec r2 ifconfig -a
eth0: flags=4098<BROADCAST,MULTICAST>  mtu 1500
        ether 96:80:2c:f2:d6:2c  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

lo: flags=8<LOOPBACK>  mtu 65536
        loop  txqueuelen 1  (Local Loopback)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

一个网卡在本机一个在网络空间里
激活下本机网卡
[root@digitest01 ~]# ifconfig vth1.1 10.1.0.1/24 up
[root@digitest01 ~]# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: ens160: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:0c:29:24:7f:ec brd ff:ff:ff:ff:ff:ff
    inet 10.132.250.85/24 brd 10.132.250.255 scope global ens160
       valid_lft forever preferred_lft forever
3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:1e:54:56:fd brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
29: vth1.1@if28: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state LOWERLAYERDOWN group default qlen 1000
    link/ether 3e:a1:d0:f2:18:1a brd ff:ff:ff:ff:ff:ff link-netnsid 1
    inet 10.1.0.1/24 brd 10.1.0.255 scope global vth1.1
       valid_lft forever preferred_lft forever

激活网络空间r2的虚拟网卡
[root@digitest01 ~]# ip netns exec r2 ifconfig eth0 10.1.0.2/24 up
[root@digitest01 ~]# ip netns exec r2 ip addr
1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
28: eth0@if29: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 96:80:2c:f2:d6:2c brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 10.1.0.2/24 brd 10.1.0.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::9480:2cff:fef2:d62c/64 scope link
       valid_lft forever preferred_lft forever

测试是否联通在本地上进行ping
[root@digitest01 ~]# ping 10.1.0.2
PING 10.1.0.2 (10.1.0.2) 56(84) bytes of data.
64 bytes from 10.1.0.2: icmp_seq=1 ttl=64 time=0.184 ms
64 bytes from 10.1.0.2: icmp_seq=2 ttl=64 time=0.051 ms
64 bytes from 10.1.0.2: icmp_seq=3 ttl=64 time=0.055 ms
64 bytes from 10.1.0.2: icmp_seq=4 ttl=64 time=0.050 ms
64 bytes from 10.1.0.2: icmp_seq=5 ttl=64 time=0.064 ms
64 bytes from 10.1.0.2: icmp_seq=6 ttl=64 time=0.054 ms
64 bytes from 10.1.0.2: icmp_seq=7 ttl=64 time=0.114 ms
成功

当然还可以吧另一个虚拟网卡挪到r1这样r1到r2就可以直接通信了.


=======================================================================================
docker 分配容器网络并且设置主机名并且设置DNS服务器定义和搜索域或者添加host文件
docker container run --name tt --network bridge -h mydocker --dns x.x.x.x --dns-search xxx.xxx --add-host host:ip  --rm busybox:latest


docker0位NAT桥,可以想象成容器室宿主机背后的主机.如果要外网访问内部的容器的话需要做DNAT访问
为了把容器中的端口暴露出来需要类似做DNAT
而docker中的DNAT就是在run的时候加-p选项将容器端口暴露到主机端口上


-p（小写）则可以指定要映射的IP和端口，但是在一个指定端口上只可以绑定一个容器。支持的格式有 hostPort:containerPort、ip:hostPort:containerPort、 ip::containerPort。

containerPort（映射所有接口地址随机端口） 

hostPort:containerPort（映射所有接口地址）
将本地的 5000 端口映射到容器的 5000 端口，可以执行如下命令：
$ sudo docker run -d -p 5000:5000 training/webapp python app.py 此时默认会绑定本地所有接口上的所有地址。

ip:hostPort:containerPort （映射指定地址的指定端口）
指定映射使用一个特定地址，比如 localhost 地址 127.0.0.1
$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py

ip::containerPort （映射指定地址的任意端口）
绑定 localhost 的任意端口到容器的 5000 端口，本地主机会自动分配一个端口。
sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py
还可以使用 udp 标记来指定 udp 端口
$ sudo docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py

查看映射端口配置
使用 docker port 来查看当前映射的端口配置，也可以查看到绑定的地址

$ docker port nostalgic_morse 5000
127.0.0.1:49155.
注意：

容器有自己的内部网络和 ip 地址（使用 docker inspect 可以获取所有的变量，Docker 还可以有一个可变的网络配置。）
-p 标记可以多次使用来绑定多个端口
例如
$ sudo docker run -d -p 5000:5000 -p 3000:80 training/webapp python app.py

=============================================================================================================
大写P的话表示
当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。
使用 docker ps 可以看到，本地主机的 49155 被映射到了容器的 5000 端口。此时访问本机的 49155 端口即可访问容器内 web 应用提供的界面。

$ sudo docker run -d -P training/webapp python app.py
$ sudo docker ps -l
CONTAINER ID  IMAGE                   COMMAND       CREATED        STATUS        PORTS                    NAMES
bc533791f3f5  training/webapp:latest  python app.py 5 seconds ago  Up 2 seconds  0.0.0.0:49155->5000/tcp  nostalgic_morse
同样的，可以通过 docker logs 命令来查看应用的信息。

$ sudo docker logs -f nostalgic_morse
* Running on http://0.0.0.0:5000/
10.0.2.2 - - [23/May/2014 20:16:31] "GET / HTTP/1.1" 200 -
10.0.2.2 - - [23/May/2014 20:16:31] "GET /favicon.ico HTTP/1.1" 404 -


===================================================================================================================
联盟式容器
先启动一个容器
[root@vm02 ~]# docker run --rm -it --name b1 busybox
/ # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
9: eth0@if10: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
 在启动一个容器以之前容器网络为基础创建另一个网络
 [root@vm02 ~]# docker run --rm -it --name b2 --network container:b1 busybox
/ # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
9: eth0@if10: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
发现ip地址是一样的

====================================================================================================
默认docker0桥 是172.17网段的如何自定义网段呢
可以通过配置/etc/docker/daemon.json文件
{
    "bip": "192.168.1.5/24",                       定义网段
    "default-gateway": "10.20.0.1",                默认网关
    "dns": ["8.8.8.8","xx.xx.xx.xx"]               DNS
}

=====================================================================================================
如何运行docker服务器给别人从外部连进来
由于docker默认监听的是socket文件,所以要改成监听正常端口
改daemon.json文件添加端口监听
{
    "hosts" : ["tcp://0.0.0.0:2375", "unix:///var/run/docker.socker.sock"]
}
增加在tcp端口的监听,然后重启docker服务即可
远程连接的话使用
运行时候带上 -H 写上主机   
docker -H xxxx:2375 image ls

=====================================================================================================
创建自定义的桥
格式有bridge还有macvlan 或者 overlay

创建桥使用docker network create 命令
桥接模式的并且设置子网的网桥  设置这个网络名叫mybr01
[root@vm02 ~]# docker network create -d bridge --subnet "172.26.0.0/16" --gateway "172.26.0.1" mybr01
17fd402bc83eb2a843fa8a58e1f3cd42fa9bfdf16325d562ab2b36ba95f791b7

使用docker network ls 就可以看到自己创建的网桥了
网桥名字可能是随机的
用ip link set dev br-xxxxx name docker1
修改网桥名字为docker1

创建个容器加入我建的网络
[root@vm02 ~]# docker run --rm -it --name b1 --net mybr01 busybox
/ # ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
12: eth0@if13: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue
    link/ether 02:42:ac:1a:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.26.0.2/16 brd 172.26.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       
 看到加入成功了 ip是哪个子网的ip
 
 如果在开一个容器的话加入原先的bridge桥的话
 这两个容器通不？
 不通
 
分别测试到宿主机两个容器都是通的,但是容器到容器室不通的
查看核心转发应该是可以连通的
[root@vm02 ~]# cat /proc/sys/net/ipv4/ip_forward
1

估计是iptables的一些规则阻断了他们的连通.

什么是核心转发功能呢？
如下讲解：
linux ip 转发设置 ip_forward
工作原理：
内网主机向公网发送数据包时，由于目的主机跟源主机不在同一网段，所以数据包暂时发往内网默认网关处理，而本网段的主机对此数据包不做任何回应。
由于源主机ip是私有的，禁止在公网使用，所以必须将数据包的源发送地址修改成公网上的可用ip，这就是网关收到数据包之后首先要做的工作--ip转换。
然后网关再把数据包发往目的主机。目的主机收到数据包之后，只认为这是网关发送的请求，并不知道内网主机的存在，也没必要知道，目的主机处理完请求，
把回应信息发还给网关。网关收到后，将目的主机发还的数据包的目的ip地址修改为发出请求的内网主机的ip地址，并将其发给内网主机。
这就是网关的第二个工作--数据包的路由转发。内网的主机只要查看数据包的目的ip与发送请求的源主机ip地址相同，就会回应，这就完成了一次请求。
出于安全考虑，Linux系统默认是禁止数据包转发的。所谓转发即当主机拥有多于一块的网卡时，其中一块收到数据包，根据数据包的目的ip地址将包发往本机另一网卡，
该网卡根据路由表继续发送数据包。这通常就是路由器所要实现的功能。

设置
Linux系统缺省并没有打开IP转发功能，要确认IP转发功能的状态，可以查看/proc文件系统，使用下面命令： cat /proc/sys/net/ipv4/ip_forward
如果上述文件中的值为0,说明禁止进行IP转发；如果是1,则说明IP转发功能已经打开。
要想打开IP转发功能，可以直接修改上述文件： echo 1 > /proc/sys/net/ipv4/ip_forward
把文件的内容由0修改为1。禁用IP转发则把1改为0。
上面的命令并没有保存对IP转发配置的更改，下次系统启动时仍会使用原来的值，要想永久修改IP转发，需要修改/etc/sysctl.conf文件，修 改下面一行的值： 
net.ipv4.ip_forward = 1 修改后可以重启系统来使修改生效，也可以执行下面的命令来使修改生效： sysctl -p /etc/sysctl.conf 进行了上面的配置后，
IP转发功能就永久使能了。


 
 











