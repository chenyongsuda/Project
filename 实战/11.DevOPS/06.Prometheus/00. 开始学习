Prometheus知识学习地址
https://yunlzheng.gitbook.io/prometheus-book/introduction
https://www.kancloud.cn/cdh0805010118/prometheus/719368

Prometheus开始
1. 监控指标手机方式
    1. 脚本---优点简单,开发周期短,缺点不够细粒度
    2. 后台运行程序---优点可以实时收集,缺点开发周期长,代码编写有问题容易产生内存泄漏,僵尸进程
2. 采集的目的
    1. 监控
    2. 报警
    如果没有监控公式或者报警阀值,采集的数据没有意义
3. 测试稳定性测试
    1.在liunx上运行的程序多多少少会对系统性能有影响,稳定性测试就是对一段时间单点部署测试对系统的稳定性进行观察.

4. 最完美的监控是哪种？
    1.系统能自愈
    2.真实链路式监控
        报警信息只针对有用信息,把无关的报警全部忽略

================================================================
1.prometheus的metrix数据格式
    最主要使用的数据类型：
        数据类型Guages 只有一个数值,可增加可减少可随机
        数据类型Counter 计数器类型,只增不减
        数据类型Histgram 统计数类似直方图
            比如HTTP Response time的统计时间
            例子比如统计当天的response time 一天100万次,用100万次值相加除以100万 得到0.5秒有意义么。。。
            这种方法忽略了问题点.所以要统计成分段直方图.
    
    数据格式
    # HELP go_goroutines Number of goroutines that currently exist.  基本描述
    # TYPE go_goroutines gauge                                       描述数据类型
    go_goroutines 38                                                 key/value模式
    
    
2. 如何使用exporter
    
    
3. 如何使用标签过滤
   http_requests_total{job="prometheus",group="canary"}
   标签匹配
   =：选择正好相等的字符串标签
  !=：选择不相等的字符串标签
  =~：选择匹配正则表达式的标签（或子标签）
  !=：选择不匹配正则表达式的标签（或子标签）

  例如，选择staging、testing、development环境下的，GET之外的HTTP方法的http_requests_total的时间序列：
  http_requests_total{environment=~"staging|testing|development",method!="GET"}
  
  对数值过滤
    http_requests_total{job="prometheus",group="canary"} > 400
  选出大于400的哪些曲线的部分线段或者点
  
4. 常用的函数
   rate()函数 专门配合counter数据
        表示取曲线的时间段然后计算每秒的速率
   
   increase()函数  专门配合counter数据
        表示某个时间段的增量的总数
   
   sum()函数
       比如图中有10条线 
       通过sum包裹变成一条线

       一般用
       sum() by (instance)
       或者
       sum() by (cluster name)
   
   topk()函数
       topk(n,xxxxxxxx) 可以修饰counter或者guage counter的话要包裹increase或者rate才有意义
   
   count()函数
 
 5.启动参数
     ./prometheus --help
        usage: prometheus [<flags>]

        The Prometheus monitoring server

        Flags:
          -h, --help                     Show context-sensitive help (also try --help-long and --help-man).
              --version                  Show application version.
              --config.file="prometheus.yml"
                                         Prometheus configuration file path.
              --web.listen-address="0.0.0.0:9090"
                                         Address to listen on for UI, API, and telemetry.
              --web.read-timeout=5m      Maximum duration before timing out read of the request, and closing idle connections.
              --web.max-connections=512  Maximum number of simultaneous connections.
              --web.external-url=<URL>   The URL under which Prometheus is externally reachable (for example, if Prometheus is served via a reverse
                                         proxy). Used for generating relative and absolute links back to Prometheus itself. If the URL has a path
                                         portion, it will be used to prefix all HTTP endpoints served by Prometheus. If omitted, relevant URL
                                         components will be derived automatically.
              --web.route-prefix=<path>  Prefix for the internal routes of web endpoints. Defaults to path of --web.external-url.
              --web.user-assets=<path>   Path to static asset directory, available at /user.
              --web.enable-lifecycle     Enable shutdown and reload via HTTP request.
              --web.enable-admin-api     Enable API endpoints for admin control actions.
              --web.console.templates="consoles"
                                         Path to the console template directory, available at /consoles.
              --web.console.libraries="console_libraries"
                                         Path to the console library directory.
              --web.page-title="Prometheus Time Series Collection and Processing Server"
                                         Document title of Prometheus instance.
              --storage.tsdb.path="data/"
                                         Base path for metrics storage.
              --storage.tsdb.retention=15d
                                         How long to retain samples in storage.
              --storage.tsdb.no-lockfile
                                         Do not create lockfile in data directory.
              --storage.remote.flush-deadline=<duration>
                                         How long to wait flushing sample on shutdown or config reload.
              --storage.remote.read-sample-limit=5e7
                                         Maximum overall number of samples to return via the remote read interface, in a single query. 0 means no
                                         limit.
              --storage.remote.read-concurrent-limit=10
                                         Maximum number of concurrent remote read calls. 0 means no limit.
              --rules.alert.for-outage-tolerance=1h
                                         Max time to tolerate prometheus outage for restoring 'for' state of alert.
              --rules.alert.for-grace-period=10m
                                         Minimum duration between alert and restored 'for' state. This is maintained only for alerts with configured
                                         'for' time greater than grace period.
              --rules.alert.resend-delay=1m
                                         Minimum amount of time to wait before resending an alert to Alertmanager.
              --alertmanager.notification-queue-capacity=10000
                                         The capacity of the queue for pending Alertmanager notifications.
              --alertmanager.timeout=10s
                                         Timeout for sending alerts to Alertmanager.
              --query.lookback-delta=5m  The delta difference allowed for retrieving metrics during expression evaluations.
              --query.timeout=2m         Maximum time a query may take before being aborted.
              --query.max-concurrency=20
                                         Maximum number of queries executed concurrently.
              --query.max-samples=50000000
                                         Maximum number of samples a single query can load into memory. Note that queries will fail if they would
                                         load more samples than this into memory, so this also limits the number of samples a query can return.
              --log.level=info           Only log messages with the given severity or above. One of: [debug, info, warn, error]
              --log.format=logfmt        Output format of log messages. One of: [logfmt, json]
   
     
     一般启动参数 --config.file="prometheus.yml" --web.listen-address="0.0.0.0:9090" --web.read-timeout=5m --web.max-connections=512 --storage.tsdb.path="data/" --storage.tsdb.retention=15d --query.timeout=2m --query.max-concurrency=20
     启动命令如下
     nohup /appl/prometheus-2.10.0.linux-amd64/prometheus --config.file="/appl/prometheus-2.10.0.linux-amd64/prometheus.yml" --web.listen-address="0.0.0.0:9090" --web.read-timeout=5m --web.max-connections=512 --storage.tsdb.path="/appl/data/" --storage.tsdb.retention=15d --query.timeout=2m --query.max-concurrency=20 &
     
 6.配置文件
            global:
              scrape_interval: 15s              抓取间隔时间
              scrape_timeout: 10s               抓取超时时间
              evaluation_interval: 15s
            alerting:
              alertmanagers:
              - static_configs:
                - targets: []
                scheme: http
                timeout: 10s
            scrape_configs:
            - job_name: prometheus
              honor_timestamps: true
              scrape_interval: 15s
              scrape_timeout: 10s
              metrics_path: /metrics
              scheme: http
              static_configs:
              - targets:
                - localhost:9090
 
 7.pushgateway推送方式
       1.shell使用方式 
            https://github.com/prometheus/pushgateway/blob/master/README.md
            Examples:

            1.1 Push a single sample into the group identified by {job="some_job"}:
              echo "some_metric 3.14" | curl --data-binary @- http://pushgateway.example.org:9091/metrics/job/some_job
            Since no type information has been provided, some_metric will be of type untyped.

            1.2 Push something more complex into the group identified by {job="some_job",instance="some_instance"}:
              cat <<EOF | curl --data-binary @- http://pushgateway.example.org:9091/metrics/job/some_job/instance/some_instance
              # TYPE some_metric counter
              some_metric{label="val1"} 42
              # TYPE another_metric gauge
              # HELP another_metric Just an example.
              another_metric 2398.283
              EOF
            Note how type information and help strings are provided. Those lines are optional, but strongly encouraged for anything more complex.

            1.3 Delete all metrics in the group identified by {job="some_job",instance="some_instance"}:
              curl -X DELETE http://pushgateway.example.org:9091/metrics/job/some_job/instance/some_instance
              
            1.4 Delete all metrics in the group identified by {job="some_job"} (note that this does not include metrics in the {job="some_job",instance="some_instance"} group from the previous example, even if those metrics have the same job label):
              curl -X DELETE http://pushgateway.example.org:9091/metrics/job/some_job

8. 安装node_exporter
        1. curl -OL https://github.com/prometheus/node_exporter/releases/download/v0.15.2/node_exporter-0.15.2.darwin-amd64.tar.gz
        2. tar -xzf node_exporter-0.15.2.darwin-amd64.tar.gz
        3. 执行node_exporter
        4. 访问http://localhost:9100/metrics，可以看到当前node exporter获取到的当前主机的所有监控数据
        
        每一个监控指标之前都会有一段类似于如下形式的信息：
        # HELP node_cpu Seconds the cpus spent in each mode.
        # TYPE node_cpu counter
        node_cpu{cpu="cpu0",mode="idle"} 362812.7890625
        # HELP node_load1 1m load average.
        # TYPE node_load1 gauge
        node_load1 3.0703125
        
        除了这些以外，在当前页面中根据物理主机系统的不同，你还可能看到如下监控指标：
        node_boot_time：系统启动时间
        node_cpu：系统CPU使用量
        nodedisk*：磁盘IO
        nodefilesystem*：文件系统用量
        node_load1：系统负载
        nodememeory*：内存使用量
        nodenetwork*：网络带宽
        node_time：当前系统时间
        go_*：node exporter中go相关指标
        process_*：node exporter自身进程相关运行指标
        
        从Node Exporter收集监控数据
        为了能够让Prometheus Server能够从当前node exporter获取到监控数据，这里需要修改Prometheus配置文件。编辑prometheus.yml并在scrape_configs节点下添加以下内容:
        scrape_configs:
          - job_name: 'prometheus'
            static_configs:
              - targets: ['localhost:9090']
          # 采集node exporter监控数据
          - job_name: 'node'
            static_configs:
              - targets: ['localhost:9100']
              
        重新启动Prometheus Server
        访问http://localhost:9090，进入到Prometheus Server。如果输入“up”并且点击执行按钮以后

9. 安装push gateway
    The Pushgateway
    Flags:
      -h, --help                     Show context-sensitive help (also try --help-long and --help-man).
          --web.listen-address=":9091"  
                                     Address to listen on for the web interface, API, and telemetry.
          --web.telemetry-path="/metrics"  
                                     Path under which to expose metrics.
          --web.external-url=        The URL under which the Pushgateway is externally reachable.
          --web.route-prefix=""      Prefix for the internal routes of web endpoints. Defaults to the path of --web.external-url.
          --persistence.file=""      File to persist metrics. If empty, metrics are only kept in memory.
          --persistence.interval=5m  The minimum interval at which to write out the persistence file.
          --log.level="info"         Only log messages with the given severity or above. Valid levels: [debug, info, warn, error, fatal]
          --log.format="logger:stderr"  
                                     Set the log target and format. Example: "logger:syslog?appname=bob&local=7" or "logger:stdout?json=true"
          --version                  Show application version.
  
    然后在server端配置
    prometheus.yml添加target
     - job_name: 'push-metrics'
        static_configs:
        - targets: ['localhost:9091']
        honor_labels: true
    # 因为prometheus配置pushgateway 的时候,也会指定job和instance,但是它只表示pushgateway实例,不能真正表达收集数据的含义。所以配置pushgateway需要添加honor_labels:true,避免收集数据本身的job和instance被覆盖。
     注意:为了防止 pushgateway 重启或意外挂掉，导致数据丢失，可以通过 -persistence.file 和 -persistence.interval 参数将数据持久化下来。

    也可以通过使用官方给的python library，使用push 方式把数据推送到pushgateway。
        # cat client.py 
        #!/usr/bin/python3
        from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
        registry = CollectorRegistry()
        g = Gauge('ping', '检测最大响应时间',['dst_ip','city'], registry=registry) #Guage(metric_name,HELP,labels_name,registry=registry)
        g.labels('192.168.1.10','shenzhen').set(42.2) #set设定值
        g.labels('192.168.1.11','shenzhen').dec(2)  #dec递减2
        g.labels('192.168.1.12','shenzhen').inc()  #inc递增，默认增1
        push_to_gateway('localhost:9091', job='ping_status', registry=registry)
    
10.pushgateway实例
    import time
    import random
    import prometheus_client
    from prometheus_client import Counter, Gauge
    from prometheus_client.core import CollectorRegistry
    import requests

    REGISTRY = CollectorRegistry(auto_describe=False)

    hostname = 'TEST001'
    instance = 'TEST002'
    status_onoff = Gauge("store_scale_status_onoff", hostname,['scale_name','instance'],registry=REGISTRY)
    status_onoff2 = Gauge("store_scale_status_onoff2", instance,['scale_name','ip'],registry=REGISTRY)

    while True:
        for i in range(8):
            status_onoff.labels(scale_name=''+str(i), instance='TEST001').set(i * random.randint(0, 8))
            status_onoff2.labels(scale_name=''+str(i), ip='192.168.1.2').set(i * random.randint(0, 8))

        requests.post("http://localhost:9091/metrics/job/sotre_scale_status",data=prometheus_client.generate_latest(REGISTRY))
        print('post finish')
        time.sleep(5)

    status_onoff中的最后在网页上显示为
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="7"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="6"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="5"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="4"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="3"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="2"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="1"}
    ✔store_scale_status_onoff{instance="TEST001",job="sotre_scale_status",scale_name="0"}
    
    status_onoff2中的最后在网页上显示为
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="7"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="6"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="5"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="4"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="3"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="2"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="1"}
    ✔store_scale_status_onoff2{ip="192.168.1.2",job="sotre_scale_status",scale_name="0"}
    注意
    instance scale name 来自于
    status_onoff.labels(scale_name=''+str(i), instance='TEST001')
    
    注册Guage的时候写的instance是不起作用的.只是一个描述而已
    
11.pushgateway说明
    1、pushgateway每次只向Prometheus返回最后一次推送的数据
        pushgateway并不是将Prometheus的pull改成了push，它只是允许用户向他推送指标信息，并记录。而Prometheus每次从           pushgateway拉取的数据并不是期间用户推送上来的所有数据，而是最后一次push上来的数据。所以设置推送时间与Prometheus拉取的时间相同(<=)一般是较好的方案。
        注意：如果客户端一直没有推送新的指标到pushgateway，那么Prometheus将始终拉取最后push上来的数据，直到指标消失（默认5分钟）。这里这个机制可以解释一下：
        pushgateway本意是不会存储指标的，但是为了让pushgateway意外重启一类的故障之后能够重新读取到原来的指标，添加了一个将指标暂时存储到本地的功能，参数--persistence.interval=5m就是默认保持5分钟，5分钟后，本地存储的指标会删除。可以通过调节这个值来修正发现异常的时间。

    2、推送到pushgateway的方法
        push：删除原有的所有指标并推送新的指标，对应put方法
        pushadd：更新已有的所有指标，对应post方法
        delete：删除指标，对应delete方法
        （以上三个解释来源于《Prometheus : up & running -  Infrastructure and Application Performance Monitoring 》）
    3、python推送到pushgateway的方式
        安装并导入相关模块
        from prometheus_client import CollectorRegistry, Gauge, pushadd_to_gateway
        def push2gateway(datas):
            registry = CollectorRegistry()
            g = Gauge('node_process_status_info','process monitor',['group','process_name','status','days','icon'],registry=registry)
            for group,process,status,runtime,icon in datas:
                print group,process,status,runtime,icon
                g.labels(group,process,status,str(runtime),icon).set(icon)
            pushadd_to_gateway('10.10.148.34:9091', job='pushgateway' ,registry=registry,timeout=200)

        以上函数中，
        node_process_status_info 表示指标名
        list参数中的值表示标签名
        循环只是为了给同一个指标的不同标签设置不同的value
        g.labels括号中表示按顺序为标签名赋值
        g.labels末尾的set表示该标签下的value值
        最后推送的时候指标越多,timeout应该设置越高，否则会推送失败，具体时间根据现场网络状况测试一下就知道了
        完整的案例，检测URL返回状态码并推送到pushgateway
        #coding:utf-8
        import requests
        from prometheus_client import CollectorRegistry, Gauge, pushadd_to_gateway
        url = '[http://10.10.164.119:8500/v1/a/b/net.c.api.d](http://10.10.164.119:8500/v1/a/b/net.c.api.d)'
        headers = {
            "User-Agent":"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 QIHU 360SE"
        }
        status_code = requests.get(url,headers=headers).status_code
        print status_code
        registry = CollectorRegistry()
        g = Gauge('node_web_status_code','web monitor',['url'],registry=registry)
        g.labels(url).set(status_code)
        pushadd_to_gateway('10.10.148.34:9091', job='pushgateway' ,registry=registry,timeout=200)
        注意：
        使用prometheus_client推送到pushgateway的时候，如果你的指标拥有多个标签，并且在循环里写入了很多次推送，但是在pushgateway中往往只能看到最后一个，这大概是因为pushgateway推送的时候相同的指标名是以覆盖的方式进行的（具体没有更多研究和验证，我的问题解决便放下了）。所以这个时候可以将pushadd_to_gateway放在指标注册的最后，如下：

        def findpush(path,g):
            output = os.popen('hadoop fs -du -h %s'%path)
            for line in output.readlines():
                row = filter(lambda x:x,map(lambda x:x.strip().replace(" ",""),line.split("  ")))
                row_info =  (conversion(row[0]),conversion(row[1]),row[2])
                g.labels(row_info[2],'false').set(row_info[0])
                g.labels(row_info[2],'true').set(row_info[1])

        def main():
            registry = CollectorRegistry()
            g = Gauge('hadoop_hdfs_du_filesize_metrics','hdfs filepath filesize from hadoop fs du',['path','backupornot'],registry=registry)

            for path in paths:
                findpush(path,g)
            pushadd_to_gateway('pushgateway的IP地址:9091', job='custom' ,registry=g,timeout=200)
        如上代码，我将脚本捕获的多行数据转换，循环注册之后，最后统一一次性推送到pushgateway。

 
 
