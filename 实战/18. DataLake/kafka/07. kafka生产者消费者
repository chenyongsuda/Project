------------------------------------------------------------------------
生产者
bootstrap.servers	
		用于建立与kafka集群连接的host/port组。数据将会在所有servers上均衡加载，不管哪些server是指定用于bootstrapping。这个列表仅仅影响初始化的hosts
		（用于发现全部的servers）。这个列表格式：host1:port1,host2:port2,…因为这些server仅仅是用于初始化的连接，以发现集群所有成员关系（可能会动态的变化），
		这个列表不需要包含所有的servers（你可能想要不止一个server，尽管这样，可能某个server宕机了）。如果没有server在这个列表出现，则发送数据会一直失败，
		直到列表可用。	list			高
acks				
		producer需要server接收到数据之后发出的确认接收的信号，此项配置就是指procuder需要多少个这样的确认信号。此配置实际上代表了数据备份的可用性。
		以下设置为常用选项：（1）acks=0： 设置为0表示producer不需要等待任何确认收到的信息。副本将立即加到socket buffer并认为已经发送。没有任何保障
		可以保证此种情况下server已经成功接收数据，同时重试配置不会发生作用（因为客户端不知道是否失败）回馈的offset会总是设置为-1；（2）acks=1： 
		这意味着至少要等待leader已经成功将数据写入本地log，但是并没有等待所有follower是否成功写入。这种情况下，如果follower没有成功备份数据，
		而此时leader又挂掉，则消息会丢失。（3）acks=all： 这意味着leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。
		这是最强的保证。，	string	-1	[all -1 0 1]	高
key.serializer		
		key的序列化方式，若是没有设置，同serializer.class	实现Serializer接口的class			高
value.serializer	
		value序列化类方式	实现Serializer接口的class			高
buffer.memory		
		producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，
		producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，
		因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。	
		long	33554432		高
		
compression.type	
		producer用于压缩数据的压缩类型。默认是无压缩。正确的选项值是none、gzip、snappy。压缩最好用于批量处理，批量处理消息越多，
		压缩性能越好	string	none		高
retries				
		设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。
		允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
		int	0		高
batch.size			
		producer将试图批处理消息记录，以减少请求次数。这将改善client与server之间的性能。这项配置控制默认的批量处理消息字节数。
		不会试图处理大于这个字节数的消息字节数。发送到brokers的请求将包含多个批量处理，其中会包含对每个partition的一个请求。
		较小的批量处理数值比较少用，并且可能降低吞吐量（0则会仅用批量处理）。较大的批量处理数值将会浪费更多内存空间，这样就需要分配特定批量处理数值的内存大小。	
		int	16384		高
client.id	
		当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。
		这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪	string	“”		中
connections.max.idle.ms	
		关闭连接空闲时间	long	540000		中
linger.ms	
		producer组将会汇总任何在请求与发送之间到达的消息记录一个单独批量的请求。通常来说，这只有在记录产生速度大于发送速度的时候才能发生。
		然而，在某些条件下，客户端将希望降低请求的数量，甚至降低到中等负载一下。这项设置将通过增加小的延迟来完成–即，不是立即发送一条记录，
		producer将会等待给定的延迟时间以允许其他消息记录发送，这些消息记录可以批量处理。这可以认为是TCP种Nagle的算法类似。
		这项设置设定了批量处理的更高的延迟边界：一旦我们获得某个partition的batch.size，他将会立即发送而不顾这项设置，
		然而如果我们获得消息字节数比这项设置要小的多，我们需要“linger”特定的时间以获取更多的消息。 这个设置默认为0，即没有延迟。设定linger.ms=5，
		例如，将会减少请求数目，但是同时会增加5ms的延迟。	long	0		中
max.block.ms	
		控制block的时长,当buffer空间不够或者metadata丢失时产生block	long	60000		中
max.request.size	
		请求的最大字节数。这也是对最大记录尺寸的有效覆盖。注意：server具有自己对消息记录尺寸的覆盖，这些尺寸和这个设置不同。
		此项设置将会限制producer每次批量发送请求的数目，以防发出巨量的请求。	int	1048576		中
partitioner.class	
		分区类	实现Partitioner 的class	class org.apache.kafka.clients.producer.internals.DefaultPartitioner		中
receive.buffer.bytes	
		socket的接收缓存空间大小,当阅读数据时使用	int	32768		中
request.timeout.ms	
		客户端将等待请求的响应的最大时间,如果在这个时间内没有收到响应，客户端将重发请求;超过重试次数将抛异常	int	3000		中
send.buffer.bytes	
		发送数据时的缓存空间大小	int	131072		中
timeout.ms	
		此配置选项控制server等待来自followers的确认的最大时间。如果确认的请求数目在此时间内没有实现，则会返回一个错误。这个超时限制是以server端度量的，没有包含请求的网络延迟	int	30000		中
max.in.flight.requests.per.connection	
		kafka可以在一个connection中发送多个请求，叫作一个flight,这样可以减少开销，但是如果产生错误，可能会造成数据的发送顺序改变,默认是5 (修改）	int	5		低
metadata.fetch.timeout.ms	
		是指我们所获取的一些元素据的第一个时间数据。元素据包含：topic，host，partitions。此项配置是指当等待元素据fetch成功完成所需要的时间，否则会跑出异常给客户端	long	60000		低
metadata.max.age.ms	
		以微秒为单位的时间，是在我们强制更新metadata的时间间隔。即使我们没有看到任何partition leadership改变。	long	300000		低
metric.reporters	
		类的列表，用于衡量指标。实现MetricReporter接口，将允许增加一些类，这些类在新的衡量指标产生时就会改变。JmxReporter总会包含用于注册JMX统计	list	none		低
metrics.num.samples	
		用于维护metrics的样本数	int	2		低
metrics.sample.window.ms	
		metrics系统维护可配置的样本数量，在一个可修正的window size。这项配置配置了窗口大小，例如。我们可能在30s的期间维护两个样本。当一个窗口推出后，
		我们会擦除并重写最老的窗口	long	30000		低
reconnect.backoff.ms	
		连接失败时，当我们重新连接时的等待时间。这避免了客户端反复重连	long	10		低
retry.backoff.ms	
		在试图重试失败的produce请求之前的等待时间。避免陷入发送-失败的死循环中	long	100		低
    

生产者如何保证消息被安全送到队列了？
org.apache.kafka.clients.producer.Producer的send（）方法有三个重载这个方法有一个回调函数，metadata参数不空则表明数据安全发送成功，否则发送失败。


使用方式
Kafka生产者发送消息的三种方式
Kafka是一种分布式的基于发布/订阅的消息系统，它的高吞吐量、灵活的offset是其它消息系统所没有的。

Kafka发送消息主要有三种方式：

1.发送并忘记 2.同步发送 3.异步发送+回调函数

 

下面以单节点的方式分别用三种方法发送1w条消息测试：

方式一：发送并忘记(不关心消息是否正常到达，对返回结果不做任何判断处理)

发送并忘记的方式本质上也是一种异步的方式，只是它不会获取消息发送的返回结果，这种方式的吞吐量是最高的，但是无法保证消息的可靠性：

复制代码
 1 import pickle
 2 import time
 3 from kafka import KafkaProducer
 4 
 5 producer = KafkaProducer(bootstrap_servers=['192.168.33.11:9092'],
 6                          key_serializer=lambda k: pickle.dumps(k),
 7                          value_serializer=lambda v: pickle.dumps(v))
 8 
 9 start_time = time.time()
10 for i in range(0, 10000):
11     print('------{}---------'.format(i))
12     future = producer.send('test_topic', key='num', value=i, partition=0)
13 
14 # 将缓冲区的全部消息push到broker当中
15 producer.flush()
16 producer.close()
17 
18 end_time = time.time()
19 time_counts = end_time - start_time
20 print(time_counts)
复制代码
 测试结果：1.88s

 

方式二：同步发送(通过get方法等待Kafka的响应，判断消息是否发送成功)

以同步的方式发送消息时，一条一条的发送，对每条消息返回的结果判断， 可以明确地知道每条消息的发送情况，但是由于同步的方式会阻塞，只有当消息通过get返回future对象时，才会继续下一条消息的发送：

 

复制代码
 1 import pickle
 2 import time
 3 from kafka import KafkaProducer
 4 from kafka.errors import kafka_errors
 5 
 6 producer = KafkaProducer(
 7     bootstrap_servers=['192.168.33.11:9092'],
 8     key_serializer=lambda k: pickle.dumps(k),
 9     value_serializer=lambda v: pickle.dumps(v)
10 )
11 
12 start_time = time.time()
13 for i in range(0, 10000):
14     print('------{}---------'.format(i))
15     future = producer.send(topic="test_topic", key="num", value=i)
16     # 同步阻塞,通过调用get()方法进而保证一定程序是有序的.
17     try:
18         record_metadata = future.get(timeout=10)
19         # print(record_metadata.topic)
20         # print(record_metadata.partition)
21         # print(record_metadata.offset)
22     except kafka_errors as e:
23         print(str(e))
24 
25 end_time = time.time()
26 time_counts = end_time - start_time
27 print(time_counts)
复制代码
 

测试结果：16s

 

方式三：异步发送+回调函数(消息以异步的方式发送，通过回调函数返回消息发送成功/失败)

在调用send方法发送消息的同时，指定一个回调函数，服务器在返回响应时会调用该回调函数，通过回调函数能够对异常情况进行处理，当调用了回调函数时，只有回调函数执行完毕生产者才会结束，否则一直会阻塞：

复制代码
 1 import pickle
 2 import time
 3 from kafka import KafkaProducer
 4 
 5 producer = KafkaProducer(
 6     bootstrap_servers=['192.168.33.11:9092'],
 7     key_serializer=lambda k: pickle.dumps(k),
 8     value_serializer=lambda v: pickle.dumps(v)
 9 )
10 
11 
12 def on_send_success(*args, **kwargs):
13     """
14     发送成功的回调函数
15     :param args:
16     :param kwargs:
17     :return:
18     """
19     return args
20 
21 
22 def on_send_error(*args, **kwargs):
23     """
24     发送失败的回调函数
25     :param args:
26     :param kwargs:
27     :return:
28     """
29 
30     return args
31 
32 
33 start_time = time.time()
34 for i in range(0, 10000):
35     print('------{}---------'.format(i))
36     # 如果成功,传进record_metadata,如果失败,传进Exception.
37     producer.send(
38         topic="test_topic", key="num", value=i
39     ).add_callback(on_send_success).add_errback(on_send_error)
40 
41 producer.flush()
42 producer.close()
43 
44 end_time = time.time()
45 time_counts = end_time - start_time
46 print(time_counts)
复制代码
测试结果：2.15s

 

三种方式虽然在时间上有所差别，但并不是说时间越快的越好，具体要看业务的应用场景：

场景1：如果业务要求消息必须是按顺序发送的，那么可以使用同步的方式，并且只能在一个partation上，结合参数设置retries的值让发送失败时重试，
设置max_in_flight_requests_per_connection=1，可以控制生产者在收到服务器晌应之前只能发送1个消息，从而控制消息顺序发送；

场景2：如果业务只关心消息的吞吐量，容许少量消息发送失败，也不关注消息的发送顺序，那么可以使用发送并忘记的方式，并配合参数acks=0，
这样生产者不需要等待服务器的响应，以网络能支持的最大速度发送消息；

场景3：如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步+回调的方式来发送消息，配合参数retries=0，
并将发送失败的消息记录到日志文件中；

-------------------------------------------------------------------------------------------------------------------------
消费者

