------------------------------------------------------------------------
生产者
bootstrap.servers	
		用于建立与kafka集群连接的host/port组。数据将会在所有servers上均衡加载，不管哪些server是指定用于bootstrapping。这个列表仅仅影响初始化的hosts
		（用于发现全部的servers）。这个列表格式：host1:port1,host2:port2,…因为这些server仅仅是用于初始化的连接，以发现集群所有成员关系（可能会动态的变化），
		这个列表不需要包含所有的servers（你可能想要不止一个server，尽管这样，可能某个server宕机了）。如果没有server在这个列表出现，则发送数据会一直失败，
		直到列表可用。	list			高
acks				
		producer需要server接收到数据之后发出的确认接收的信号，此项配置就是指procuder需要多少个这样的确认信号。此配置实际上代表了数据备份的可用性。
		以下设置为常用选项：（1）acks=0： 设置为0表示producer不需要等待任何确认收到的信息。副本将立即加到socket buffer并认为已经发送。没有任何保障
		可以保证此种情况下server已经成功接收数据，同时重试配置不会发生作用（因为客户端不知道是否失败）回馈的offset会总是设置为-1；（2）acks=1： 
		这意味着至少要等待leader已经成功将数据写入本地log，但是并没有等待所有follower是否成功写入。这种情况下，如果follower没有成功备份数据，
		而此时leader又挂掉，则消息会丢失。（3）acks=all： 这意味着leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。
		这是最强的保证。，	string	-1	[all -1 0 1]	高
key.serializer		
		key的序列化方式，若是没有设置，同serializer.class	实现Serializer接口的class			高
value.serializer	
		value序列化类方式	实现Serializer接口的class			高
buffer.memory		
		producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，
		producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，
		因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。	
		long	33554432		高
		
compression.type	
		producer用于压缩数据的压缩类型。默认是无压缩。正确的选项值是none、gzip、snappy。压缩最好用于批量处理，批量处理消息越多，
		压缩性能越好	string	none		高
retries				
		设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。
		允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
		int	0		高
batch.size			
		producer将试图批处理消息记录，以减少请求次数。这将改善client与server之间的性能。这项配置控制默认的批量处理消息字节数。
		不会试图处理大于这个字节数的消息字节数。发送到brokers的请求将包含多个批量处理，其中会包含对每个partition的一个请求。
		较小的批量处理数值比较少用，并且可能降低吞吐量（0则会仅用批量处理）。较大的批量处理数值将会浪费更多内存空间，这样就需要分配特定批量处理数值的内存大小。	
		int	16384		高
client.id	
		当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。
		这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪	string	“”		中
connections.max.idle.ms	
		关闭连接空闲时间	long	540000		中
linger.ms	
		producer组将会汇总任何在请求与发送之间到达的消息记录一个单独批量的请求。通常来说，这只有在记录产生速度大于发送速度的时候才能发生。
		然而，在某些条件下，客户端将希望降低请求的数量，甚至降低到中等负载一下。这项设置将通过增加小的延迟来完成–即，不是立即发送一条记录，
		producer将会等待给定的延迟时间以允许其他消息记录发送，这些消息记录可以批量处理。这可以认为是TCP种Nagle的算法类似。
		这项设置设定了批量处理的更高的延迟边界：一旦我们获得某个partition的batch.size，他将会立即发送而不顾这项设置，
		然而如果我们获得消息字节数比这项设置要小的多，我们需要“linger”特定的时间以获取更多的消息。 这个设置默认为0，即没有延迟。设定linger.ms=5，
		例如，将会减少请求数目，但是同时会增加5ms的延迟。	long	0		中
max.block.ms	
		控制block的时长,当buffer空间不够或者metadata丢失时产生block	long	60000		中
max.request.size	
		请求的最大字节数。这也是对最大记录尺寸的有效覆盖。注意：server具有自己对消息记录尺寸的覆盖，这些尺寸和这个设置不同。
		此项设置将会限制producer每次批量发送请求的数目，以防发出巨量的请求。	int	1048576		中
partitioner.class	
		分区类	实现Partitioner 的class	class org.apache.kafka.clients.producer.internals.DefaultPartitioner		中
receive.buffer.bytes	
		socket的接收缓存空间大小,当阅读数据时使用	int	32768		中
request.timeout.ms	
		客户端将等待请求的响应的最大时间,如果在这个时间内没有收到响应，客户端将重发请求;超过重试次数将抛异常	int	3000		中
send.buffer.bytes	
		发送数据时的缓存空间大小	int	131072		中
timeout.ms	
		此配置选项控制server等待来自followers的确认的最大时间。如果确认的请求数目在此时间内没有实现，则会返回一个错误。这个超时限制是以server端度量的，没有包含请求的网络延迟	int	30000		中
max.in.flight.requests.per.connection	
		kafka可以在一个connection中发送多个请求，叫作一个flight,这样可以减少开销，但是如果产生错误，可能会造成数据的发送顺序改变,默认是5 (修改）	int	5		低
metadata.fetch.timeout.ms	
		是指我们所获取的一些元素据的第一个时间数据。元素据包含：topic，host，partitions。此项配置是指当等待元素据fetch成功完成所需要的时间，否则会跑出异常给客户端	long	60000		低
metadata.max.age.ms	
		以微秒为单位的时间，是在我们强制更新metadata的时间间隔。即使我们没有看到任何partition leadership改变。	long	300000		低
metric.reporters	
		类的列表，用于衡量指标。实现MetricReporter接口，将允许增加一些类，这些类在新的衡量指标产生时就会改变。JmxReporter总会包含用于注册JMX统计	list	none		低
metrics.num.samples	
		用于维护metrics的样本数	int	2		低
metrics.sample.window.ms	
		metrics系统维护可配置的样本数量，在一个可修正的window size。这项配置配置了窗口大小，例如。我们可能在30s的期间维护两个样本。当一个窗口推出后，
		我们会擦除并重写最老的窗口	long	30000		低
reconnect.backoff.ms	
		连接失败时，当我们重新连接时的等待时间。这避免了客户端反复重连	long	10		低
retry.backoff.ms	
		在试图重试失败的produce请求之前的等待时间。避免陷入发送-失败的死循环中	long	100		低
    

生产者如何保证消息被安全送到队列了？
org.apache.kafka.clients.producer.Producer的send（）方法有三个重载这个方法有一个回调函数，metadata参数不空则表明数据安全发送成功，否则发送失败。


使用方式
Kafka生产者发送消息的三种方式
Kafka是一种分布式的基于发布/订阅的消息系统，它的高吞吐量、灵活的offset是其它消息系统所没有的。

Kafka发送消息主要有三种方式：

1.发送并忘记 2.同步发送 3.异步发送+回调函数

 

下面以单节点的方式分别用三种方法发送1w条消息测试：

方式一：发送并忘记(不关心消息是否正常到达，对返回结果不做任何判断处理)

发送并忘记的方式本质上也是一种异步的方式，只是它不会获取消息发送的返回结果，这种方式的吞吐量是最高的，但是无法保证消息的可靠性：

复制代码
 1 import pickle
 2 import time
 3 from kafka import KafkaProducer
 4 
 5 producer = KafkaProducer(bootstrap_servers=['192.168.33.11:9092'],
 6                          key_serializer=lambda k: pickle.dumps(k),
 7                          value_serializer=lambda v: pickle.dumps(v))
 8 
 9 start_time = time.time()
10 for i in range(0, 10000):
11     print('------{}---------'.format(i))
12     future = producer.send('test_topic', key='num', value=i, partition=0)
13 
14 # 将缓冲区的全部消息push到broker当中
15 producer.flush()
16 producer.close()
17 
18 end_time = time.time()
19 time_counts = end_time - start_time
20 print(time_counts)
复制代码
 测试结果：1.88s

 

方式二：同步发送(通过get方法等待Kafka的响应，判断消息是否发送成功)

以同步的方式发送消息时，一条一条的发送，对每条消息返回的结果判断， 可以明确地知道每条消息的发送情况，但是由于同步的方式会阻塞，只有当消息通过get返回future对象时，才会继续下一条消息的发送：

 

复制代码
 1 import pickle
 2 import time
 3 from kafka import KafkaProducer
 4 from kafka.errors import kafka_errors
 5 
 6 producer = KafkaProducer(
 7     bootstrap_servers=['192.168.33.11:9092'],
 8     key_serializer=lambda k: pickle.dumps(k),
 9     value_serializer=lambda v: pickle.dumps(v)
10 )
11 
12 start_time = time.time()
13 for i in range(0, 10000):
14     print('------{}---------'.format(i))
15     future = producer.send(topic="test_topic", key="num", value=i)
16     # 同步阻塞,通过调用get()方法进而保证一定程序是有序的.
17     try:
18         record_metadata = future.get(timeout=10)
19         # print(record_metadata.topic)
20         # print(record_metadata.partition)
21         # print(record_metadata.offset)
22     except kafka_errors as e:
23         print(str(e))
24 
25 end_time = time.time()
26 time_counts = end_time - start_time
27 print(time_counts)
复制代码
 

测试结果：16s

 

方式三：异步发送+回调函数(消息以异步的方式发送，通过回调函数返回消息发送成功/失败)

在调用send方法发送消息的同时，指定一个回调函数，服务器在返回响应时会调用该回调函数，通过回调函数能够对异常情况进行处理，当调用了回调函数时，只有回调函数执行完毕生产者才会结束，否则一直会阻塞：

复制代码
 1 import pickle
 2 import time
 3 from kafka import KafkaProducer
 4 
 5 producer = KafkaProducer(
 6     bootstrap_servers=['192.168.33.11:9092'],
 7     key_serializer=lambda k: pickle.dumps(k),
 8     value_serializer=lambda v: pickle.dumps(v)
 9 )
10 
11 
12 def on_send_success(*args, **kwargs):
13     """
14     发送成功的回调函数
15     :param args:
16     :param kwargs:
17     :return:
18     """
19     return args
20 
21 
22 def on_send_error(*args, **kwargs):
23     """
24     发送失败的回调函数
25     :param args:
26     :param kwargs:
27     :return:
28     """
29 
30     return args
31 
32 
33 start_time = time.time()
34 for i in range(0, 10000):
35     print('------{}---------'.format(i))
36     # 如果成功,传进record_metadata,如果失败,传进Exception.
37     producer.send(
38         topic="test_topic", key="num", value=i
39     ).add_callback(on_send_success).add_errback(on_send_error)
40 
41 producer.flush()
42 producer.close()
43 
44 end_time = time.time()
45 time_counts = end_time - start_time
46 print(time_counts)
复制代码
测试结果：2.15s

 

三种方式虽然在时间上有所差别，但并不是说时间越快的越好，具体要看业务的应用场景：

场景1：如果业务要求消息必须是按顺序发送的，那么可以使用同步的方式，并且只能在一个partation上，结合参数设置retries的值让发送失败时重试，
设置max_in_flight_requests_per_connection=1，可以控制生产者在收到服务器晌应之前只能发送1个消息，从而控制消息顺序发送；

场景2：如果业务只关心消息的吞吐量，容许少量消息发送失败，也不关注消息的发送顺序，那么可以使用发送并忘记的方式，并配合参数acks=0，
这样生产者不需要等待服务器的响应，以网络能支持的最大速度发送消息；

场景3：如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步+回调的方式来发送消息，配合参数retries=0，
并将发送失败的消息记录到日志文件中；

-------------------------------------------------------------------------------------------------------------------------
消费者
Kafka提交offset机制
在kafka的消费者中，有一个非常关键的机制，那就是offset机制。它使得Kafka在消费的过程中即使挂了或者引发再均衡问题重新分配Partation，当下次重新恢复消费时仍然可以知道从哪里开始消费。它好比看一本书中的书签标记，每次通过书签标记(offset)就能快速找到该从哪里开始看(消费)。

Kafka对于offset的处理有两种提交方式：(1) 自动提交(默认的提交方式)   (2) 手动提交(可以灵活地控制offset)

(1) 自动提交偏移量:

Kafka中偏移量的自动提交是由参数enable_auto_commit和auto_commit_interval_ms控制的，当enable_auto_commit=True时，Kafka在消费的过程中会以频率为auto_commit_interval_ms向Kafka自带的topic(__consumer_offsets)进行偏移量提交，具体提交到哪个Partation是以算法：partation=hash(group_id)%50来计算的。

如：group_id=test_group_1，则partation=hash("test_group_1")%50=28

自动提交偏移量示例：

复制代码
 1 import pickle
 2 import uuid
 3 from kafka import KafkaConsumer
 4 
 5 consumer = KafkaConsumer(
 6     bootstrap_servers=['192.168.33.11:9092'],
 7     group_id="test_group_1",
 8     client_id="{}".format(str(uuid.uuid4())),
 9     max_poll_records=500,
10     enable_auto_commit=True,  # 默认为True 表示自动提交偏移量
11     auto_commit_interval_ms=100,  # 控制自动提交偏移量的频率 单位ms 默认是5000ms
12     key_deserializer=lambda k: pickle.loads(k),
13     value_deserializer=lambda v: pickle.loads(v)
14 )
15 
16 # 订阅消费round_topic这个主题
17 consumer.subscribe(topics=('round_topic',))
18 
19 try:
20     while True:
21         consumer_records_dict = consumer.poll(timeout_ms=1000)
22 
23         # consumer.assignment()可以获取每个分区的offset
24         for partition in consumer.assignment():
25             print('主题:{} 分区:{},需要从下面的offset开始消费:{}'.format(
26                 str(partition.topic),
27                 str(partition.partition),
28                 consumer.position(partition)
29             ))
30 
31         # 处理逻辑.
32         for k, record_list in consumer_records_dict.items():
33             print(k)
34             for record in record_list:
35                 print("topic = {},partition = {},offset = {},key = {},value = {}".format(
36                     record.topic, record.partition, record.offset, record.key, record.value)
37                 )
38 
39 finally:
40     # 调用close方法的时候会触发偏移量的自动提交 close默认autocommit=True
41     consumer.close()
复制代码
 返回结果：



在上述代码中，最后调用consumer.close()时候也会触发自动提交，因为它默认autocommit=True，源码如下：

复制代码
 1     def close(self, autocommit=True):
 2         """Close the consumer, waiting indefinitely for any needed cleanup.
 3 
 4         Keyword Arguments:
 5             autocommit (bool): If auto-commit is configured for this consumer,
 6                 this optional flag causes the consumer to attempt to commit any
 7                 pending consumed offsets prior to close. Default: True
 8         """
 9         if self._closed:
10             return
11         log.debug("Closing the KafkaConsumer.")
12         self._closed = True
13         self._coordinator.close(autocommit=autocommit)
14         self._metrics.close()
15         self._client.close()
16         try:
17             self.config['key_deserializer'].close()
18         except AttributeError:
19             pass
20         try:
21             self.config['value_deserializer'].close()
22         except AttributeError:
23             pass
24         log.debug("The KafkaConsumer has closed.")
复制代码
 

对于自动提交偏移量，如果auto_commit_interval_ms的值设置的过大，当消费者在自动提交偏移量之前异常退出，将导致kafka未提交偏移量，进而出现重复消费的问题，所以建议auto_commit_interval_ms的值越小越好。

 

(2) 手动提交偏移量:

鉴于Kafka自动提交offset的不灵活性和不精确性(只能是按指定频率的提交)，Kafka提供了手动提交offset策略。手动提交能对偏移量更加灵活精准地控制，以保证消息不被重复消费以及消息不被丢失。

对于手动提交offset主要有3种方式：1.同步提交  2.异步提交  3.异步+同步 组合的方式提交

 1.同步手动提交偏移量

同步模式下提交失败的时候一直尝试提交，直到遇到无法重试的情况下才会结束，同时同步方式下消费者线程在拉取消息会被阻塞，在broker对提交的请求做出响应之前，会一直阻塞直到偏移量提交操作成功或者在提交过程中发生异常，限制了消息的吞吐量。

复制代码
 1 """
 2 同步的方式10W条消息  4.58s
 3 """
 4 
 5 import pickle
 6 import uuid
 7 import time
 8 from kafka import KafkaConsumer
 9 
10 consumer = KafkaConsumer(
11     bootstrap_servers=['192.168.33.11:9092'],
12     group_id="test_group_1",
13     client_id="{}".format(str(uuid.uuid4())),
14     enable_auto_commit=False,  # 设置为手动提交偏移量.
15     key_deserializer=lambda k: pickle.loads(k),
16     value_deserializer=lambda v: pickle.loads(v)
17 )
18 
19 # 订阅消费round_topic这个主题
20 consumer.subscribe(topics=('round_topic',))
21 
22 try:
23     start_time = time.time()
24     while True:
25         consumer_records_dict = consumer.poll(timeout_ms=100)  # 在轮询中等待的毫秒数
26         print("获取下一轮")
27 
28         record_num = 0
29         for key, record_list in consumer_records_dict.items():
30             for record in record_list:
31                 record_num += 1
32         print("---->当前批次获取到的消息个数是:{}<----".format(record_num))
33         record_num = 0
34 
35         for k, record_list in consumer_records_dict.items():
36             for record in record_list:
37                 print("topic = {},partition = {},offset = {},key = {},value = {}".format(
38                     record.topic, record.partition, record.offset, record.key, record.value)
39                 )
40 
41         try:
42             # 轮询一个batch 手动提交一次
43             consumer.commit()  # 提交当前批次最新的偏移量. 会阻塞  执行完后才会下一轮poll
44             end_time = time.time()
45             time_counts = end_time - start_time
46             print(time_counts)
47         except Exception as e:
48             print('commit failed', str(e))
49 
50 finally:
51     consumer.close()  # 手动提交中close对偏移量提交没有影响
复制代码
 



从上述可以看出，每轮循一个批次，手动提交一次，只有当前批次的消息提交完成时才会触发poll来获取下一轮的消息，经测试10W条消息耗时4.58s

 2.异步手动提交偏移量+回调函数

 异步手动提交offset时，消费者线程不会阻塞，提交失败的时候也不会进行重试，并且可以配合回调函数在broker做出响应的时候记录错误信息。

 

复制代码
 1 """
 2 异步的方式手动提交偏移量(异步+回调函数的模式) 10W条消息 3.09s
 3 """
 4 
 5 import pickle
 6 import uuid
 7 import time
 8 from kafka import KafkaConsumer
 9 
10 consumer = KafkaConsumer(
11     bootstrap_servers=['192.168.33.11:9092'],
12     group_id="test_group_1",
13     client_id="{}".format(str(uuid.uuid4())),
14     enable_auto_commit=False,  # 设置为手动提交偏移量.
15     key_deserializer=lambda k: pickle.loads(k),
16     value_deserializer=lambda v: pickle.loads(v)
17 )
18 
19 # 订阅消费round_topic这个主题
20 consumer.subscribe(topics=('round_topic',))
21 
22 
23 def _on_send_response(*args, **kwargs):
24     """
25     提交偏移量涉及回调函数
26     :param args: args[0] --> {TopicPartition:OffsetAndMetadata}  args[1] --> Exception
27     :param kwargs:
28     :return:
29     """
30     if isinstance(args[1], Exception):
31         print('偏移量提交异常. {}'.format(args[1]))
32     else:
33         print('偏移量提交成功')
34 
35 
36 try:
37     start_time = time.time()
38     while True:
39         consumer_records_dict = consumer.poll(timeout_ms=10)
40 
41         record_num = 0
42         for key, record_list in consumer_records_dict.items():
43             for record in record_list:
44                 record_num += 1
45         print("当前批次获取到的消息个数是:{}".format(record_num))
46 
47         for record_list in consumer_records_dict.values():
48             for record in record_list:
49                 print("topic = {},partition = {},offset = {},key = {},value = {}".format(
50                     record.topic, record.partition, record.offset, record.key, record.value))
51 
52         # 避免频繁提交
53         if record_num != 0:
54             try:
55                 consumer.commit_async(callback=_on_send_response)
56             except Exception as e:
57                 print('commit failed', str(e))
58 
59         record_num = 0
60 
61 finally:
62     consumer.close()
复制代码


对于args参数：args[0]是一个dict，key是TopicPartition，value是OffsetAndMetadata，表示该主题下的partition对应的offset；args[1]在提交成功是True，提交失败时是一个Exception类。

对于异步提交，由于不会进行失败重试，当消费者异常关闭或者触发了再均衡前，如果偏移量还未提交就会造成偏移量丢失。

 3.异步+同步 组合的方式提交偏移量

针对异步提交偏移量丢失的问题，通过对消费者进行异步批次提交并且在关闭时同步提交的方式，这样即使上一次的异步提交失败，通过同步提交还能够进行补救，同步会一直重试，直到提交成功。

复制代码
 1 """
 2 同步和异步组合的方式提交偏移量
 3 """
 4 
 5 import pickle
 6 import uuid
 7 import time
 8 from kafka import KafkaConsumer
 9 
10 consumer = KafkaConsumer(
11     bootstrap_servers=['192.168.33.11:9092'],
12     group_id="test_group_1",
13     client_id="{}".format(str(uuid.uuid4())),
14     enable_auto_commit=False,  # 设置为手动提交偏移量.
15     key_deserializer=lambda k: pickle.loads(k),
16     value_deserializer=lambda v: pickle.loads(v)
17 )
18 
19 # 订阅消费round_topic这个主题
20 consumer.subscribe(topics=('round_topic',))
21 
22 
23 def _on_send_response(*args, **kwargs):
24     """
25     提交偏移量涉及的回调函数
26     :param args:
27     :param kwargs:
28     :return:
29     """
30     if isinstance(args[1], Exception):
31         print('偏移量提交异常. {}'.format(args[1]))
32     else:
33         print('偏移量提交成功')
34 
35 
36 try:
37     start_time = time.time()
38     while True:
39         consumer_records_dict = consumer.poll(timeout_ms=100)
40 
41         record_num = 0
42         for key, record_list in consumer_records_dict.items():
43             for record in record_list:
44                 record_num += 1
45         print("---->当前批次获取到的消息个数是:<----".format(record_num))
46         record_num = 0
47 
48         for k, record_list in consumer_records_dict.items():
49             print(k)
50             for record in record_list:
51                 print("topic = {},partition = {},offset = {},key = {},value = {}".format(
52                     record.topic, record.partition, record.offset, record.key, record.value)
53                 )
54 
55         try:
56             # 轮询一个batch 手动提交一次
57             consumer.commit_async(callback=_on_send_response)
58             end_time = time.time()
59             time_counts = end_time - start_time
60             print(time_counts)
61         except Exception as e:
62             print('commit failed', str(e))
63 
64 except Exception as e:
65     print(str(e))
66 finally:
67     try:
68         # 同步提交偏移量,在消费者异常退出的时候再次提交偏移量,确保偏移量的提交.
69         consumer.commit()
70         print("同步补救提交成功")
71     except Exception as e:
72         consumer.close()
复制代码
通过finally在最后不管是否异常都会触发consumer.commit()来同步补救一次，确保偏移量不会丢失
