1. Impala is a high-performance SQL engine for vast amounts of data
– Massively-parallel processing (MPP)
– Inspired by Google’s Dremel project
– Query latency measured in milliseconds
– Developed by C++

三大组件
Impala Statestore
Impala Catalog Service
Impala Daemon ---数据处理的

一般大数据组件都支持ODBS和JDBC抽取数据

逻辑层面上一个表对应HDFS的一个目录并且目录没有嵌套

命令行上推荐使用beeline -u 不建议用hive
beeline -u jdbc:hive2://localhost:10000 -n training

impala使用impala-shell
#>impala-shell

清元数据
invalidate metadata

HIVE 和 Impala区别
---hive
hive 支持数据的隐式转化
> SELECT zipcode FROM customers LIMIT 1;
60601
> SELECT zipcode + 1.5 FROM customers LIMIT 1;
60602.5

---impala
> SELECT zipcode + 1.5 FROM customers LIMIT 1;
ERROR: AnalysisException: Arithmetic operation...

---------------------
Impala and Hive handle out-of-range values differently
– Hive returns NULL
– Impala returns the maximum value for that type

HIVE默认创建表路径
/user/hive/warehouse

定义表的存储路径 定义locationg
CREATE TABLE tablename (colname DATATYPE, ...)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY char
STORED AS {TEXTFILE|SEQUENCEFILE|…}
LOCATION xxxxxxxxxxx

CREATE TABLE jobs_archived LIKE jobs;拷贝表结构
拷贝数据

管理表和外部表
区别,管理表,drop后元数据和数据都没了

Sqoop 直接导入到hive表中
sqoop import \
--connect jdbc:mysql://localhost/dualcore \
--username training \
--password training \
--fields-terminated-by '\t' \
--table employees \
--hive-import

insert into 表 select xxx from 表
LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]

CREATE TABLE tablename as select * from

----------------------------------------------------
hive可以设计主键,impala没有  但是主键没啥用一般也就是分区
什么时候做静态分区,什么时候做动态分区
静态分区
当元数据里面没有分区类型数据.做静态比较好.

hive.exec.dynamic.partition.mode
默认值：strict
动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。
一般需要设置为nonstrict

hive.exec.max.dynamic.partitions.pernode
默认值：100
在每个执行MR的节点上，最大可以创建多少个动态分区。
该参数需要根据实际的数据来设定。

比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。
hive.exec.max.dynamic.partitions
默认值：1000
在所有执行MR的节点上，最大一共可以创建多少个动态分区。
同上参数解释。

hive.exec.max.created.files
默认值：100000
整个MR Job中，最大可以创建多少个HDFS文件。
一般默认值足够了，除非你的数据量非常大，需要创建的文件数大于100000，可根据实际情况加以调整。

hive.error.on.empty.partition
默认值：false
当有空分区生成时，是否抛出异常。
一般不需要设置。

parquel-tools 可以看该文件的内容信息
parquel-tools head 

==================================================================================================
*****impala移动数据最好都通过load data命令导入
如果直接通过HDFS移动到外部表文件的话就会有缓存问题
如果无法避免这种问题或者外部调度任务直接写入该文件夹的话,需要在每次的批处理任务后面直接加刷新缓存操作
如refresh tablename
  invalidate metadata tablename 这种操作 invalidate metadata不加表名表示刷全部的元数据.
