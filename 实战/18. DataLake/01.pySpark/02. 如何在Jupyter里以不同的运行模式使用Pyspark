如何在Jupyter里以不同的运行模式使用Pyspark
假设你的环境已经安装好了以下东西,如何详细的安装它们不在本文的讨论范围之内
具体的可疑参考三分钟搞定jupyter和pyspark整合
anaconda2
findspark
pyspark
这里多说一句,spark1.几的版本以下的只支持python2.几的支持python2和3.具体是spark2.几,笔者没有详细调查.

如何以不同的模式运行pyspark
我们都知道,spark是分为local,standalone,yarn-client,yarn-cluster等运行模式的.既然想用jupyter,自然是想要交互式的,那么如何以不同的模式来交互呢?

笔者总结如下:

local模式
import findspark
findspark.init()
from pyspark import SparkContext
sc = SparkContext("local", "First App")

2.standalone
需要传入地址和端口

import findspark
findspark.init()
from pyspark import SparkContext
sc = SparkContext("spark://192.168.5.129:7077", "First App")

3.yarn-client
import findspark
findspark.init()
from pyspark import SparkContext
sc = SparkContext("yarn-client", "First App")

3.yarn-cluster
cluster模式一般都是开发完成后,直接用来执行用的,不适用于交互模式,笔者也没有尝试过.在此就不介绍了.

关于SparkContext
其实SparkContext这个类,每个位置可以传的参数,是和shell命令行对应的,注意到了这一点,看看文档就知道每个参数可以接受什么样的值了.具体内容可以看spark官方文档.

==============================================================
jupyter book 第一个例子
import findspark
findspark.init()

from contextlib import contextmanager
from pyspark import SparkContext
from pyspark import SparkConf

SPARK_MASTER='local'
SPARK_APP_NAME='Word Count'
SPARK_EXECUTOR_MEMORY='200m'

@contextmanager
def spark_manager():
    conf = SparkConf().setMaster(SPARK_MASTER) \
                      .setAppName(SPARK_APP_NAME) 
    spark_context = SparkContext(conf=conf)

    try:
        yield spark_context
    finally:
        spark_context.stop()

with spark_manager() as context:
    File = "file:///C:/666.csv"  # Should be some file on your system
    textFileRDD = context.textFile(File)
    wordCounts = textFileRDD.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a+b)
    wordCounts.saveAsTextFile("output")
print("WordCount - Done")

================================================================================================
VSCode编写 Python 支持 Jupyter notebook 了！
过去，想要在 VSCode 中运行 Jupyter notebook 需要安装一个 Neuron 扩展，我也装过，感觉很强大、很方便。

就在不久前，VSCode 中 Python 扩展 的最新版本加入了对 Jupyter notebook 的支持，可以直接在 VSCode 的交互界面进行和 Jupyter notebook 中一样的操作。
在代码前加上 #%%，软件一旦检测到，就会在其上显示 Run cell，点击后就可以像 Jupyter notebook 一样运行一段代码。使用 #%% [markdown] 就可以编写 Markdown 文本了。
直接打开一个 Jupyter notebook 文件时，还可以将它导入为 Python 代码格式。

导入之后，就会显示 Jupyter notebook 中对应的 Python 代码或者 Markdown 文本。
在右侧的交互界面中，还可以进行“撤销”、“重启 iPython Kernel”、“导出为 Jupyter notebook” 等操作。
直接运行 Jupyter notebook 这个更新可以说是很优秀了，为机器学习、数据分析等领域创造了很大的方便，赶紧更新 VSCode 和 Python 扩展来感受一下吧！
