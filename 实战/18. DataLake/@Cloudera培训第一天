1. Cloudera推荐版本5.x 源码开源
2. 继承了Hadoop大量的组件
3. 实施不支持Window,需要Linux64位操作系统
4. HBASE擅长海量数据做检索,对比大批量IO的话还是HDFS擅长,KUDU的话目的结合HDFS(偏向IO)和HBASE(偏向检索)开源不久使用上问题较多
5. 数据处理形式大体分为两种,第一种批处理作业(历史数据集)pig hive mr 第二种是流式数据处理(对于要求比较高的spark)如spark stream,Flink等

Cloudera体系中
1. 开源组件
    HIVE Hadoop等
2. 闭源组件,商业组件
   安全加密相关的


节点问题
在5.x没有节点问题.
在6.1以后 free版本有节点限制

大数据问题汇总
1. 存储问题,解决IO问题,分布存储
2. 分析问题,解决IO只能使用分布式分析.

分布式设计
1. HDFS 用于存储
2. YARN 用于资源的分配以及任务重试
3. MR框架用于分布式计算框架

Hadoop体系
NameNode使用可靠的商业机器
DataNode使用廉价机器

HDFS单个文件最好大于1GB 才不算小文件,不然容易产生性能问题.
HDFS访问方式 hdfs dfs xxxxxxxxx
如hdfs dfs -cat /usr/xxx/xxx.txt
hdfs dfs -put
hdfs dfs -get 

hdfs dfs -put local.txt hdfs.txt      hdfs.txt 将会放在/user/username下的文件
调用API可以做hiding用户
如果在shell上做的话 是和登录用户名相同 记住HDFS中username不会自己生成,需要管理员自己创建

Yarn对程序做分布式执行过程,Yarn组件对其进行资源管理调度
包含ResourceManager 一个集群只有一个 ,JobManager 这两个组件可靠性需要很高.这两个是管理类节点,无数据处理计算.
Nodnamager多个,为计算节点要和hadoop datanode的节点一一对应.

Hadoop最起码要装三个,HDFS YARN Mapreduce

开发框架引擎：
Mapreduce(延迟大)和spark(延迟小,主流处理引擎)

----------------------------------------------------------------------------------------------------------
PIG
1. 架构比较灵活,一个工具装哪个机器哪里就可以做处理
2. 基于MR

HIVE -------- Facebook
1. 基于SQL的MR解释框架
2. 支持spark

Impala
1. 基于SQL
2. 接近Hive
3. 底层是Cloudera自研SQL引擎

-----------------------------------------------------------------------------------------------------------
Sqoop
1. 结构化数据库------------>HDFS
2. sqoop1和sqoop2 主流版本是1 稳定可靠
3. 支持双向 RDBMS<-------------->HDFS
4. 底层mapreduce
5. sqoop导入可指定格式不指定则是文本格式
6. 导入支持字段过滤
7. 支持行过滤
8. 增量数据支持
    -append模式 只支持新增不支持修改(要有主键建议数值型,要求新数据尽量需要数值递增,该模式要指定上次的最大值)
    -lastmodified模式  前提要求是要求原表有时间戳.底层还是对于这个时间做过滤

hbase
1. 建立在Hadoop
2. key做检索

flumn
1. 数据采集组件

------------------------------------------------------------------------------------------------------------------------
实验场景
1. 先将数据做载入
2. 数据整理
3. 数据分析

模拟Dualcore公司,线下线上销售和订单有关.

