impala
impala组件安装的两种方式
1. 建立在yarn上和spark和MR资源都由yarn管理.
2. 直接建立在HDFS上.impala由自己管理资源.建议独立部署.由自己管理.由于不能和yarn很好集成,开源比较晚.


Catalog server 维护元数据
State Store    维护impala Daemon节点的状态
Name Node
很多Impala Daemon 需要和HDFS的DATANNODE 一一对应

SQL执行的时候会选一个leader deamon由他来协调其他daemon的交流.

impala中有cache
Metadata is cached from the
Metastore at startup

数据文件新增impala也会有元数据,也需要刷新缓存
只要元数据操作在外部就会引发缓存问题.

IMPALA对于HDFS的目录数据文件和block属性也是元数据

Refresh只刷新HDFS的blocks信息不刷新表结构
INVALIDATE METADATA TABLE 刷新表结构和block信息

IMPALA好处速度快,不足不稳定

IMPALA无冗余处理,在某个小SQL错误导致整个sql错误.可靠性差不稳定.

使用场景面向结构化做机器分析.

优化方面：收集统计计划只有impala有
expain 查看执行计划  看下warning
compute stats 收集统计计划
show table stats table_name 查看统计计划
show column stats table_name 查看字段级别执行计划

实际执行计划：
在执行一次实际的查询后执行summary
在执行一次实际的查询后执行profile(细粒度的统计)


=======================================================================
@@@@@@@@@@@@@@执行计划中一个stage就是一个mapreduce


=======================================================================
HIVE的本地模式
对于比较小的任务将该任务只在本机执行会快很多
$ hive
hive> SET mapred.job.tracker=local;
hive> SET mapred.local.dir=/home/training/tmpdata;          #路径表示这次任务的log存储路径
hive> SELECT zipcode, COUNT(cust_id) AS num
FROM customers GROUP BY zipcode;

分区和分桶
分区是按照目录结构

分桶是一张表对于一个目录,目录不允许嵌套
比如原先有5个数据文件一共20G
现在变成分桶表的话设置为20个桶
就会产生20个文件.
带来的效果：
如果要带来优化的话使用join的话 提升效率对join左边和右边的两个表都做相同的桶数.


============================================================================
HIVE的索引是存储在HDFS上.
记录的是标记位置.没什么用.还没懂课下查查吧.


HIVE有两种平台,一个HIVE基于MR2或者基于Spark平台.

PIG体现出灵活性.PIG优势在于ETL.HIVE IMPALA优势在于分析.

可靠性上HIVE ON MR2. 
HIVE ON Spark 速度没impala快. SQL再转SPARK 再提交到spark.












