机器学习分为：监督学习，无监督学习，半监督学习（也可以用hinton所说的强化学习）等。

在这里，主要理解一下监督学习和无监督学习。

监督学习（supervised learning）
从给定的训练数据集中学习出一个函数（模型参数），当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求包括输入输出，也可以说是特征和目标。训练集中的目标是由人标注的。监督学习就是最常见的分类（注意和聚类区分）问题，通过已有的训练样本（即已知数据及其对应的输出）去训练得到一个最优模型（这个模型属于某个函数的集合，最优表示某个评价准则下是最佳的），再利用这个模型将所有的输入映射为相应的输出，对输出进行简单的判断从而实现分类的目的。也就具有了对未知数据分类的能力。监督学习的目标往往是让计算机去学习我们已经创建好的分类系统（模型）。
监督学习是训练神经网络和决策树的常见技术。这两种技术高度依赖事先确定的分类系统给出的信息，对于神经网络，分类系统利用信息判断网络的错误，然后不断调整网络参数。对于决策树，分类系统用它来判断哪些属性提供了最多的信息。
常见的有监督学习算法：回归分析和统计分类。最典型的算法是KNN和SVM。
有监督学习最常见的就是：regression&classification
Regression：Y是实数vector。回归问题，就是拟合(x,y)的一条曲线，使得价值函数(costfunction) L最小
Classification：Y是一个有穷数(finitenumber)，可以看做类标号，分类问题首先要给定有lable的数据训练分类器，故属于有监督学习过程。分类过程中cost function l(X,Y)是X属于类Y的概率的负对数。
其中fi(X)=P(Y=i/X)。

 

无监督学习（unsupervised learning）
输入数据没有被标记，也没有确定的结果。样本数据类别未知，需要根据样本间的相似性对样本集进行分类（聚类，clustering）试图使类内差距最小化，类间差距最大化。通俗点将就是实际应用中，不少情况下无法预先知道样本的标签，也就是说没有训练样本对应的类别，因而只能从原先没有样本标签的样本集开始学习分类器设计。
非监督学习目标不是告诉计算机怎么做，而是让它（计算机）自己去学习怎样做事情。非监督学习有两种思路。第一种思路是在指导Agent时不为其指定明确分类，而是在成功时，采用某种形式的激励制度。需要注意的是，这类训练通常会置于决策问题的框架里，因为它的目标不是为了产生一个分类系统，而是做出最大回报的决定，这种思路很好的概括了现实世界，agent可以对正确的行为做出激励，而对错误行为做出惩罚。
无监督学习的方法分为两大类：
(1)    一类为基于概率密度函数估计的直接方法：指设法找到各类别在特征空间的分布参数，再进行分类。
(2)    另一类是称为基于样本间相似性度量的简洁聚类方法：其原理是设法定出不同类别的核心或初始内核，然后依据样本与核心之间的相似性度量将样本聚集成不同的类别。
利用聚类结果，可以提取数据集中隐藏信息，对未来数据进行分类和预测。应用于数据挖掘，模式识别，图像处理等。
PCA和很多deep learning算法都属于无监督学习。 


逻辑回归算法：
https://tech.meituan.com/intro_to_logistic_regression.html

